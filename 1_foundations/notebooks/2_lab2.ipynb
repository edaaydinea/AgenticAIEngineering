{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Welcome to the Second Lab - Week 1, Day 3\n",
    "\n",
    "Today we will work with lots of models! This is a way to get comfortable with APIs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table style=\"margin: 0; text-align: left; width:100%\">\n",
    "    <tr>\n",
    "        <td style=\"width: 150px; height: 150px; vertical-align: middle;\">\n",
    "            <img src=\"../assets/stop.png\" width=\"150\" height=\"150\" style=\"display: block;\" />\n",
    "        </td>\n",
    "        <td>\n",
    "            <h2 style=\"color:#ff7800;\">Important point - please read</h2>\n",
    "            <span style=\"color:#ff7800;\">The way I collaborate with you may be different to other courses you've taken. I prefer not to type code while you watch. Rather, I execute Jupyter Labs, like this, and give you an intuition for what's going on. My suggestion is that you carefully execute this yourself, <b>after</b> watching the lecture. Add print statements to understand what's going on, and then come up with your own variations.<br/><br/>If you have time, I'd love it if you submit a PR for changes in the community_contributions folder - instructions in the resources. Also, if you have a Github account, use this to showcase your variations. Not only is this essential practice, but it demonstrates your skills to others, including perhaps future clients or employers...\n",
    "            </span>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start with imports - ask ChatGPT to explain any package that you don't know\n",
    "\n",
    "import os\n",
    "import json\n",
    "from dotenv import load_dotenv\n",
    "from anthropic import Anthropic\n",
    "from IPython.display import Markdown, display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Always remember to do this!\n",
    "load_dotenv(override=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the openai model from the github models\n",
    "from openai import OpenAI\n",
    "import os\n",
    "\n",
    "token = os.getenv(\"GITHUB_TOKEN\")\n",
    "endpoint = \"https://models.inference.ai.azure.com\"\n",
    "\n",
    "openai = OpenAI(\n",
    "    base_url=endpoint,\n",
    "    api_key=token,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "request = \"Please come up with a challenging, nuanced question that I can ask a number of LLMs to evaluate their intelligence. \"\n",
    "request += \"Answer only with the question, no explanation.\"\n",
    "messages = [{\"role\": \"user\", \"content\": request}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'user',\n",
       "  'content': 'Please come up with a challenging, nuanced question that I can ask a number of LLMs to evaluate their intelligence. Answer only with the question, no explanation.'}]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How would you reconcile the ethical implications of creating autonomous AI systems capable of making life-altering decisions with the potential benefits they offer, while considering diverse cultural perspectives and the limitations of current legal frameworks?\n"
     ]
    }
   ],
   "source": [
    "response = openai.chat.completions.create(\n",
    "    model=\"gpt-4.1-mini\",\n",
    "    messages=messages,\n",
    ")\n",
    "question = response.choices[0].message.content\n",
    "print(question)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "competitors = []\n",
    "answers = []\n",
    "messages = [{\"role\": \"user\", \"content\": question}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Reconciling the ethical implications of autonomous AI systems that make life-altering decisions with their potential benefits, especially while respecting diverse cultural perspectives and navigating current legal limitations, requires a multi-faceted, inclusive, and adaptive approach. Here's a structured way to think about it:\n",
       "\n",
       "### 1. **Recognize the Ethical Stakes and Potential Benefits**\n",
       "- **Ethical Stakes:** Autonomous AI making decisions—such as in healthcare, criminal justice, or finance—can profoundly affect individuals’ rights, dignity, and well-being. Risks include bias, loss of accountability, and erosion of human agency.\n",
       "- **Potential Benefits:** Improved efficiency, consistency, scalability of decision-making, access to expertise, and even the ability to mitigate human biases when carefully designed.\n",
       "\n",
       "### 2. **Adopt a Human-Centered Ethical Framework**\n",
       "- **Prioritize Human Rights and Dignity:** Ensure AI decision-making respects fundamental human rights (privacy, fairness, autonomy).\n",
       "- **Accountability and Transparency:** AI’s decisions should be explainable to affected individuals, with clear accountability channels.\n",
       "- **Informed Consent and Control:** Where possible, individuals should retain control over decisions or have the right to contest AI outcomes.\n",
       "\n",
       "### 3. **Incorporate Diverse Cultural Perspectives**\n",
       "- **Multicultural Ethical Engagement:** Different societies have varying values related to autonomy, collective good, and justice. Engage ethicists, social scientists, and stakeholders globally to incorporate a multiplicity of values.\n",
       "- **Contextual Adaptation:** AI systems and policies should be adaptable to cultural norms without enforcing homogenized standards that might marginalize local practices.\n",
       "- **Participatory Design:** Include representatives from different cultural backgrounds in the design and evaluation of AI systems.\n",
       "\n",
       "### 4. **Address Legal Framework Limitations with Proactive Governance**\n",
       "- **Iterative Policy Development:** Laws often lag behind technology. Regulators should adopt flexible, adaptive approaches such as regulatory sandboxes to test AI impacts safely.\n",
       "- **International Cooperation:** Foster international norms and agreements to manage AI’s cross-border implications and reduce regulatory arbitrage.\n",
       "- **Embedding Ethics in Design:** Encourage or mandate “ethics-by-design” principles where AI developers embed ethical considerations throughout the lifecycle of AI systems.\n",
       "\n",
       "### 5. **Foster Multistakeholder Collaboration**\n",
       "- Collaboration between AI developers, ethicists, policymakers, civil society, and affected communities is crucial to balance competing interests and values.\n",
       "- Establish independent oversight bodies with diverse representation to audit and guide AI deployment.\n",
       "\n",
       "### 6. **Promote Education and Awareness**\n",
       "- Equip users and the public with knowledge to understand AI’s capabilities and limitations, empowering them to engage critically and advocate for their rights.\n",
       "\n",
       "---\n",
       "\n",
       "### Summary\n",
       "Balancing the ethical challenges of autonomous AI in life-altering decisions with its benefits requires a human-centric, culturally sensitive, and legally adaptive approach. This means embedding ethical principles and transparency, respecting cultural diversity, advancing inclusive governance structures, and proactively evolving legal frameworks to keep pace with technological sophistication. The goal is not to reject AI but to shape its development and use so that it aligns with broadly shared human values and safeguards individual rights."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# The API we know well\n",
    "\n",
    "model_name = \"gpt-4.1-mini\"\n",
    "\n",
    "response = openai.chat.completions.create(model=model_name, messages=messages)\n",
    "answer = response.choices[0].message.content\n",
    "\n",
    "display(Markdown(answer))\n",
    "competitors.append(model_name)\n",
    "answers.append(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Anthropic has a slightly different API, and Max Tokens is required\n",
    "\n",
    "model_name = \"claude-3-7-sonnet-latest\"\n",
    "\n",
    "claude = Anthropic()\n",
    "response = claude.messages.create(model=model_name, messages=messages, max_tokens=1000)\n",
    "answer = response.content[0].text\n",
    "\n",
    "display(Markdown(answer))\n",
    "competitors.append(model_name)\n",
    "answers.append(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gemini = OpenAI(api_key=google_api_key, base_url=\"https://generativelanguage.googleapis.com/v1beta/openai/\")\n",
    "model_name = \"gemini-2.0-flash\"\n",
    "\n",
    "response = gemini.chat.completions.create(model=model_name, messages=messages)\n",
    "answer = response.choices[0].message.content\n",
    "\n",
    "display(Markdown(answer))\n",
    "competitors.append(model_name)\n",
    "answers.append(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deepseek = OpenAI(api_key=deepseek_api_key, base_url=\"https://api.deepseek.com/v1\")\n",
    "model_name = \"deepseek-chat\"\n",
    "\n",
    "response = deepseek.chat.completions.create(model=model_name, messages=messages)\n",
    "answer = response.choices[0].message.content\n",
    "\n",
    "display(Markdown(answer))\n",
    "competitors.append(model_name)\n",
    "answers.append(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "groq = OpenAI(api_key=groq_api_key, base_url=\"https://api.groq.com/openai/v1\")\n",
    "model_name = \"llama-3.3-70b-versatile\"\n",
    "\n",
    "response = groq.chat.completions.create(model=model_name, messages=messages)\n",
    "answer = response.choices[0].message.content\n",
    "\n",
    "display(Markdown(answer))\n",
    "competitors.append(model_name)\n",
    "answers.append(answer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For the next cell, we will use Ollama\n",
    "\n",
    "Ollama runs a local web service that gives an OpenAI compatible endpoint,  \n",
    "and runs models locally using high performance C++ code.\n",
    "\n",
    "If you don't have Ollama, install it here by visiting https://ollama.com then pressing Download and following the instructions.\n",
    "\n",
    "After it's installed, you should be able to visit here: http://localhost:11434 and see the message \"Ollama is running\"\n",
    "\n",
    "You might need to restart Cursor (and maybe reboot). Then open a Terminal (control+\\`) and run `ollama serve`\n",
    "\n",
    "Useful Ollama commands (run these in the terminal, or with an exclamation mark in this notebook):\n",
    "\n",
    "`ollama pull <model_name>` downloads a model locally  \n",
    "`ollama ls` lists all the models you've downloaded  \n",
    "`ollama rm <model_name>` deletes the specified model from your downloads"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table style=\"margin: 0; text-align: left; width:100%\">\n",
    "    <tr>\n",
    "        <td style=\"width: 150px; height: 150px; vertical-align: middle;\">\n",
    "            <img src=\"../assets/stop.png\" width=\"150\" height=\"150\" style=\"display: block;\" />\n",
    "        </td>\n",
    "        <td>\n",
    "            <h2 style=\"color:#ff7800;\">Super important - ignore me at your peril!</h2>\n",
    "            <span style=\"color:#ff7800;\">The model called <b>llama3.3</b> is FAR too large for home computers - it's not intended for personal computing and will consume all your resources! Stick with the nicely sized <b>llama3.2</b> or <b>llama3.2:1b</b> and if you want larger, try llama3.1 or smaller variants of Qwen, Gemma, Phi or DeepSeek. See the <A href=\"https://ollama.com/models\">the Ollama models page</a> for a full list of models and sizes.\n",
    "            </span>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ollama pull llama3.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Reconciling the ethical implications of creating autonomous AI systems that can make life-altering decisions is a complex challenge that requires consideration of various factors, including diversity of cultural perspectives and limitations of current legal frameworks. Here are some steps to address these concerns:\n",
       "\n",
       "1. **Diverse stakeholder engagement**: Involve diverse stakeholders, including policymakers, ethicists, technologists, industry experts, and members from different cultural backgrounds, in the development process to ensure that ethics and values are integrated at each stage.\n",
       "2. **Value alignment**: Conduct thorough value-alignment studies to identify and prioritize ethical principles, such as fairness, transparency, accountability, and human dignity, that must be incorporated into AI decision-making processes.\n",
       "3. **Regulatory frameworks**: Collaborate with policymakers and regulatory bodies to develop and update frameworks that account for the societal implications of autonomous AI systems. Encourage a multidisciplinary approach to ensure effectiveness in addressing ethical concerns.\n",
       "4. **Human oversight and accountability**: Ensure that human oversight and accountability are inherent features of autonomous AI systems, allowing for intervention or review of decisions made by the system whenever necessary.\n",
       "5. **Cultural sensitivity training**: Provide cultural sensitivity training for developers and users of autonomous AI systems to recognize and respect diverse cultural perspectives and values embedded in these systems.\n",
       "6. **Regular evaluation and assessment**: Regularly evaluate and assess the impact of autonomous AI systems on society, addressing concerns raised by diverse stakeholders and updating ethical frameworks as needed.\n",
       "7. **Addressing bias and fairness**: Incorporate approaches to detect and mitigate bias into AI decision-making processes, ensuring that they are fair, transparent, and respect human diversity.\n",
       "8. **Global cooperation and collaboration**: Collaborate with global partners to develop shared standards, guidelines, or regulations that recognize the need for diverse perspectives and safeguards in AI development.\n",
       "\n",
       "Considerations of current legal frameworks:\n",
       "\n",
       "1. **Update existing laws**: Update existing laws and regulations to address emerging issues related to autonomous AI systems, taking into account international human rights instruments and technological advancements.\n",
       "2. **New legislation**: Ensure that new laws and regulations can be adapted as technology evolves, creating flexible legislation for future-proofing the governance of AI.\n",
       "3. **International harmonization efforts**: Join international efforts to develop and promote the convergence of national standards and best practices in AI governance to facilitate smoother implementation, exchange, and comparison across jurisdictions.\n",
       "4. **Transparency and explainability**: Ensure transparent decision-making processes and techniques like model interpretability are used as much as possible, making it easier for stakeholders to validate or dispute findings.\n",
       "\n",
       "Given these considerations and steps toward reconciliation:\n",
       "\n",
       "1. Encourage diverse participation in ethical decision-making.\n",
       "2. Inclusive governance to recognize the broader consequences of AI technologies can effectively improve societal coordination of technological innovations.\n",
       "3. Addressing current legal limitations demands an ongoing effort through international research collaboration, policy consultation, updates, or harmonization.\n",
       "\n",
       "**By adopting these perspectives and strategies, we will ensure a brighter future for society's use of AI systems that make life-altering decisions while addressing our existing challenges related to diverse cultural perspectives and regulatory limits in their development."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ollama = OpenAI(base_url='http://localhost:11434/v1', api_key='ollama')\n",
    "model_name = \"llama3.2\"\n",
    "\n",
    "response = ollama.chat.completions.create(model=model_name, messages=messages)\n",
    "answer = response.choices[0].message.content\n",
    "\n",
    "display(Markdown(answer))\n",
    "competitors.append(model_name)\n",
    "answers.append(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['gpt-4.1-mini', 'llama3.2']\n",
      "[\"Reconciling the ethical implications of autonomous AI systems that make life-altering decisions with their potential benefits, especially while respecting diverse cultural perspectives and navigating current legal limitations, requires a multi-faceted, inclusive, and adaptive approach. Here's a structured way to think about it:\\n\\n### 1. **Recognize the Ethical Stakes and Potential Benefits**\\n- **Ethical Stakes:** Autonomous AI making decisions—such as in healthcare, criminal justice, or finance—can profoundly affect individuals’ rights, dignity, and well-being. Risks include bias, loss of accountability, and erosion of human agency.\\n- **Potential Benefits:** Improved efficiency, consistency, scalability of decision-making, access to expertise, and even the ability to mitigate human biases when carefully designed.\\n\\n### 2. **Adopt a Human-Centered Ethical Framework**\\n- **Prioritize Human Rights and Dignity:** Ensure AI decision-making respects fundamental human rights (privacy, fairness, autonomy).\\n- **Accountability and Transparency:** AI’s decisions should be explainable to affected individuals, with clear accountability channels.\\n- **Informed Consent and Control:** Where possible, individuals should retain control over decisions or have the right to contest AI outcomes.\\n\\n### 3. **Incorporate Diverse Cultural Perspectives**\\n- **Multicultural Ethical Engagement:** Different societies have varying values related to autonomy, collective good, and justice. Engage ethicists, social scientists, and stakeholders globally to incorporate a multiplicity of values.\\n- **Contextual Adaptation:** AI systems and policies should be adaptable to cultural norms without enforcing homogenized standards that might marginalize local practices.\\n- **Participatory Design:** Include representatives from different cultural backgrounds in the design and evaluation of AI systems.\\n\\n### 4. **Address Legal Framework Limitations with Proactive Governance**\\n- **Iterative Policy Development:** Laws often lag behind technology. Regulators should adopt flexible, adaptive approaches such as regulatory sandboxes to test AI impacts safely.\\n- **International Cooperation:** Foster international norms and agreements to manage AI’s cross-border implications and reduce regulatory arbitrage.\\n- **Embedding Ethics in Design:** Encourage or mandate “ethics-by-design” principles where AI developers embed ethical considerations throughout the lifecycle of AI systems.\\n\\n### 5. **Foster Multistakeholder Collaboration**\\n- Collaboration between AI developers, ethicists, policymakers, civil society, and affected communities is crucial to balance competing interests and values.\\n- Establish independent oversight bodies with diverse representation to audit and guide AI deployment.\\n\\n### 6. **Promote Education and Awareness**\\n- Equip users and the public with knowledge to understand AI’s capabilities and limitations, empowering them to engage critically and advocate for their rights.\\n\\n---\\n\\n### Summary\\nBalancing the ethical challenges of autonomous AI in life-altering decisions with its benefits requires a human-centric, culturally sensitive, and legally adaptive approach. This means embedding ethical principles and transparency, respecting cultural diversity, advancing inclusive governance structures, and proactively evolving legal frameworks to keep pace with technological sophistication. The goal is not to reject AI but to shape its development and use so that it aligns with broadly shared human values and safeguards individual rights.\", \"Reconciling the ethical implications of creating autonomous AI systems that can make life-altering decisions is a complex challenge that requires consideration of various factors, including diversity of cultural perspectives and limitations of current legal frameworks. Here are some steps to address these concerns:\\n\\n1. **Diverse stakeholder engagement**: Involve diverse stakeholders, including policymakers, ethicists, technologists, industry experts, and members from different cultural backgrounds, in the development process to ensure that ethics and values are integrated at each stage.\\n2. **Value alignment**: Conduct thorough value-alignment studies to identify and prioritize ethical principles, such as fairness, transparency, accountability, and human dignity, that must be incorporated into AI decision-making processes.\\n3. **Regulatory frameworks**: Collaborate with policymakers and regulatory bodies to develop and update frameworks that account for the societal implications of autonomous AI systems. Encourage a multidisciplinary approach to ensure effectiveness in addressing ethical concerns.\\n4. **Human oversight and accountability**: Ensure that human oversight and accountability are inherent features of autonomous AI systems, allowing for intervention or review of decisions made by the system whenever necessary.\\n5. **Cultural sensitivity training**: Provide cultural sensitivity training for developers and users of autonomous AI systems to recognize and respect diverse cultural perspectives and values embedded in these systems.\\n6. **Regular evaluation and assessment**: Regularly evaluate and assess the impact of autonomous AI systems on society, addressing concerns raised by diverse stakeholders and updating ethical frameworks as needed.\\n7. **Addressing bias and fairness**: Incorporate approaches to detect and mitigate bias into AI decision-making processes, ensuring that they are fair, transparent, and respect human diversity.\\n8. **Global cooperation and collaboration**: Collaborate with global partners to develop shared standards, guidelines, or regulations that recognize the need for diverse perspectives and safeguards in AI development.\\n\\nConsiderations of current legal frameworks:\\n\\n1. **Update existing laws**: Update existing laws and regulations to address emerging issues related to autonomous AI systems, taking into account international human rights instruments and technological advancements.\\n2. **New legislation**: Ensure that new laws and regulations can be adapted as technology evolves, creating flexible legislation for future-proofing the governance of AI.\\n3. **International harmonization efforts**: Join international efforts to develop and promote the convergence of national standards and best practices in AI governance to facilitate smoother implementation, exchange, and comparison across jurisdictions.\\n4. **Transparency and explainability**: Ensure transparent decision-making processes and techniques like model interpretability are used as much as possible, making it easier for stakeholders to validate or dispute findings.\\n\\nGiven these considerations and steps toward reconciliation:\\n\\n1. Encourage diverse participation in ethical decision-making.\\n2. Inclusive governance to recognize the broader consequences of AI technologies can effectively improve societal coordination of technological innovations.\\n3. Addressing current legal limitations demands an ongoing effort through international research collaboration, policy consultation, updates, or harmonization.\\n\\n**By adopting these perspectives and strategies, we will ensure a brighter future for society's use of AI systems that make life-altering decisions while addressing our existing challenges related to diverse cultural perspectives and regulatory limits in their development.\"]\n"
     ]
    }
   ],
   "source": [
    "# So where are we?\n",
    "\n",
    "print(competitors)\n",
    "print(answers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Competitor: gpt-4.1-mini\n",
      "\n",
      "Reconciling the ethical implications of autonomous AI systems that make life-altering decisions with their potential benefits, especially while respecting diverse cultural perspectives and navigating current legal limitations, requires a multi-faceted, inclusive, and adaptive approach. Here's a structured way to think about it:\n",
      "\n",
      "### 1. **Recognize the Ethical Stakes and Potential Benefits**\n",
      "- **Ethical Stakes:** Autonomous AI making decisions—such as in healthcare, criminal justice, or finance—can profoundly affect individuals’ rights, dignity, and well-being. Risks include bias, loss of accountability, and erosion of human agency.\n",
      "- **Potential Benefits:** Improved efficiency, consistency, scalability of decision-making, access to expertise, and even the ability to mitigate human biases when carefully designed.\n",
      "\n",
      "### 2. **Adopt a Human-Centered Ethical Framework**\n",
      "- **Prioritize Human Rights and Dignity:** Ensure AI decision-making respects fundamental human rights (privacy, fairness, autonomy).\n",
      "- **Accountability and Transparency:** AI’s decisions should be explainable to affected individuals, with clear accountability channels.\n",
      "- **Informed Consent and Control:** Where possible, individuals should retain control over decisions or have the right to contest AI outcomes.\n",
      "\n",
      "### 3. **Incorporate Diverse Cultural Perspectives**\n",
      "- **Multicultural Ethical Engagement:** Different societies have varying values related to autonomy, collective good, and justice. Engage ethicists, social scientists, and stakeholders globally to incorporate a multiplicity of values.\n",
      "- **Contextual Adaptation:** AI systems and policies should be adaptable to cultural norms without enforcing homogenized standards that might marginalize local practices.\n",
      "- **Participatory Design:** Include representatives from different cultural backgrounds in the design and evaluation of AI systems.\n",
      "\n",
      "### 4. **Address Legal Framework Limitations with Proactive Governance**\n",
      "- **Iterative Policy Development:** Laws often lag behind technology. Regulators should adopt flexible, adaptive approaches such as regulatory sandboxes to test AI impacts safely.\n",
      "- **International Cooperation:** Foster international norms and agreements to manage AI’s cross-border implications and reduce regulatory arbitrage.\n",
      "- **Embedding Ethics in Design:** Encourage or mandate “ethics-by-design” principles where AI developers embed ethical considerations throughout the lifecycle of AI systems.\n",
      "\n",
      "### 5. **Foster Multistakeholder Collaboration**\n",
      "- Collaboration between AI developers, ethicists, policymakers, civil society, and affected communities is crucial to balance competing interests and values.\n",
      "- Establish independent oversight bodies with diverse representation to audit and guide AI deployment.\n",
      "\n",
      "### 6. **Promote Education and Awareness**\n",
      "- Equip users and the public with knowledge to understand AI’s capabilities and limitations, empowering them to engage critically and advocate for their rights.\n",
      "\n",
      "---\n",
      "\n",
      "### Summary\n",
      "Balancing the ethical challenges of autonomous AI in life-altering decisions with its benefits requires a human-centric, culturally sensitive, and legally adaptive approach. This means embedding ethical principles and transparency, respecting cultural diversity, advancing inclusive governance structures, and proactively evolving legal frameworks to keep pace with technological sophistication. The goal is not to reject AI but to shape its development and use so that it aligns with broadly shared human values and safeguards individual rights.\n",
      "Competitor: llama3.2\n",
      "\n",
      "Reconciling the ethical implications of creating autonomous AI systems that can make life-altering decisions is a complex challenge that requires consideration of various factors, including diversity of cultural perspectives and limitations of current legal frameworks. Here are some steps to address these concerns:\n",
      "\n",
      "1. **Diverse stakeholder engagement**: Involve diverse stakeholders, including policymakers, ethicists, technologists, industry experts, and members from different cultural backgrounds, in the development process to ensure that ethics and values are integrated at each stage.\n",
      "2. **Value alignment**: Conduct thorough value-alignment studies to identify and prioritize ethical principles, such as fairness, transparency, accountability, and human dignity, that must be incorporated into AI decision-making processes.\n",
      "3. **Regulatory frameworks**: Collaborate with policymakers and regulatory bodies to develop and update frameworks that account for the societal implications of autonomous AI systems. Encourage a multidisciplinary approach to ensure effectiveness in addressing ethical concerns.\n",
      "4. **Human oversight and accountability**: Ensure that human oversight and accountability are inherent features of autonomous AI systems, allowing for intervention or review of decisions made by the system whenever necessary.\n",
      "5. **Cultural sensitivity training**: Provide cultural sensitivity training for developers and users of autonomous AI systems to recognize and respect diverse cultural perspectives and values embedded in these systems.\n",
      "6. **Regular evaluation and assessment**: Regularly evaluate and assess the impact of autonomous AI systems on society, addressing concerns raised by diverse stakeholders and updating ethical frameworks as needed.\n",
      "7. **Addressing bias and fairness**: Incorporate approaches to detect and mitigate bias into AI decision-making processes, ensuring that they are fair, transparent, and respect human diversity.\n",
      "8. **Global cooperation and collaboration**: Collaborate with global partners to develop shared standards, guidelines, or regulations that recognize the need for diverse perspectives and safeguards in AI development.\n",
      "\n",
      "Considerations of current legal frameworks:\n",
      "\n",
      "1. **Update existing laws**: Update existing laws and regulations to address emerging issues related to autonomous AI systems, taking into account international human rights instruments and technological advancements.\n",
      "2. **New legislation**: Ensure that new laws and regulations can be adapted as technology evolves, creating flexible legislation for future-proofing the governance of AI.\n",
      "3. **International harmonization efforts**: Join international efforts to develop and promote the convergence of national standards and best practices in AI governance to facilitate smoother implementation, exchange, and comparison across jurisdictions.\n",
      "4. **Transparency and explainability**: Ensure transparent decision-making processes and techniques like model interpretability are used as much as possible, making it easier for stakeholders to validate or dispute findings.\n",
      "\n",
      "Given these considerations and steps toward reconciliation:\n",
      "\n",
      "1. Encourage diverse participation in ethical decision-making.\n",
      "2. Inclusive governance to recognize the broader consequences of AI technologies can effectively improve societal coordination of technological innovations.\n",
      "3. Addressing current legal limitations demands an ongoing effort through international research collaboration, policy consultation, updates, or harmonization.\n",
      "\n",
      "**By adopting these perspectives and strategies, we will ensure a brighter future for society's use of AI systems that make life-altering decisions while addressing our existing challenges related to diverse cultural perspectives and regulatory limits in their development.\n"
     ]
    }
   ],
   "source": [
    "# It's nice to know how to use \"zip\"\n",
    "for competitor, answer in zip(competitors, answers):\n",
    "    print(f\"Competitor: {competitor}\\n\\n{answer}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's bring this together - note the use of \"enumerate\"\n",
    "\n",
    "together = \"\"\n",
    "for index, answer in enumerate(answers):\n",
    "    together += f\"# Response from competitor {index+1}\\n\\n\"\n",
    "    together += answer + \"\\n\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Response from competitor 1\n",
      "\n",
      "Reconciling the ethical implications of autonomous AI systems that make life-altering decisions with their potential benefits, especially while respecting diverse cultural perspectives and navigating current legal limitations, requires a multi-faceted, inclusive, and adaptive approach. Here's a structured way to think about it:\n",
      "\n",
      "### 1. **Recognize the Ethical Stakes and Potential Benefits**\n",
      "- **Ethical Stakes:** Autonomous AI making decisions—such as in healthcare, criminal justice, or finance—can profoundly affect individuals’ rights, dignity, and well-being. Risks include bias, loss of accountability, and erosion of human agency.\n",
      "- **Potential Benefits:** Improved efficiency, consistency, scalability of decision-making, access to expertise, and even the ability to mitigate human biases when carefully designed.\n",
      "\n",
      "### 2. **Adopt a Human-Centered Ethical Framework**\n",
      "- **Prioritize Human Rights and Dignity:** Ensure AI decision-making respects fundamental human rights (privacy, fairness, autonomy).\n",
      "- **Accountability and Transparency:** AI’s decisions should be explainable to affected individuals, with clear accountability channels.\n",
      "- **Informed Consent and Control:** Where possible, individuals should retain control over decisions or have the right to contest AI outcomes.\n",
      "\n",
      "### 3. **Incorporate Diverse Cultural Perspectives**\n",
      "- **Multicultural Ethical Engagement:** Different societies have varying values related to autonomy, collective good, and justice. Engage ethicists, social scientists, and stakeholders globally to incorporate a multiplicity of values.\n",
      "- **Contextual Adaptation:** AI systems and policies should be adaptable to cultural norms without enforcing homogenized standards that might marginalize local practices.\n",
      "- **Participatory Design:** Include representatives from different cultural backgrounds in the design and evaluation of AI systems.\n",
      "\n",
      "### 4. **Address Legal Framework Limitations with Proactive Governance**\n",
      "- **Iterative Policy Development:** Laws often lag behind technology. Regulators should adopt flexible, adaptive approaches such as regulatory sandboxes to test AI impacts safely.\n",
      "- **International Cooperation:** Foster international norms and agreements to manage AI’s cross-border implications and reduce regulatory arbitrage.\n",
      "- **Embedding Ethics in Design:** Encourage or mandate “ethics-by-design” principles where AI developers embed ethical considerations throughout the lifecycle of AI systems.\n",
      "\n",
      "### 5. **Foster Multistakeholder Collaboration**\n",
      "- Collaboration between AI developers, ethicists, policymakers, civil society, and affected communities is crucial to balance competing interests and values.\n",
      "- Establish independent oversight bodies with diverse representation to audit and guide AI deployment.\n",
      "\n",
      "### 6. **Promote Education and Awareness**\n",
      "- Equip users and the public with knowledge to understand AI’s capabilities and limitations, empowering them to engage critically and advocate for their rights.\n",
      "\n",
      "---\n",
      "\n",
      "### Summary\n",
      "Balancing the ethical challenges of autonomous AI in life-altering decisions with its benefits requires a human-centric, culturally sensitive, and legally adaptive approach. This means embedding ethical principles and transparency, respecting cultural diversity, advancing inclusive governance structures, and proactively evolving legal frameworks to keep pace with technological sophistication. The goal is not to reject AI but to shape its development and use so that it aligns with broadly shared human values and safeguards individual rights.\n",
      "\n",
      "# Response from competitor 2\n",
      "\n",
      "Reconciling the ethical implications of creating autonomous AI systems that can make life-altering decisions is a complex challenge that requires consideration of various factors, including diversity of cultural perspectives and limitations of current legal frameworks. Here are some steps to address these concerns:\n",
      "\n",
      "1. **Diverse stakeholder engagement**: Involve diverse stakeholders, including policymakers, ethicists, technologists, industry experts, and members from different cultural backgrounds, in the development process to ensure that ethics and values are integrated at each stage.\n",
      "2. **Value alignment**: Conduct thorough value-alignment studies to identify and prioritize ethical principles, such as fairness, transparency, accountability, and human dignity, that must be incorporated into AI decision-making processes.\n",
      "3. **Regulatory frameworks**: Collaborate with policymakers and regulatory bodies to develop and update frameworks that account for the societal implications of autonomous AI systems. Encourage a multidisciplinary approach to ensure effectiveness in addressing ethical concerns.\n",
      "4. **Human oversight and accountability**: Ensure that human oversight and accountability are inherent features of autonomous AI systems, allowing for intervention or review of decisions made by the system whenever necessary.\n",
      "5. **Cultural sensitivity training**: Provide cultural sensitivity training for developers and users of autonomous AI systems to recognize and respect diverse cultural perspectives and values embedded in these systems.\n",
      "6. **Regular evaluation and assessment**: Regularly evaluate and assess the impact of autonomous AI systems on society, addressing concerns raised by diverse stakeholders and updating ethical frameworks as needed.\n",
      "7. **Addressing bias and fairness**: Incorporate approaches to detect and mitigate bias into AI decision-making processes, ensuring that they are fair, transparent, and respect human diversity.\n",
      "8. **Global cooperation and collaboration**: Collaborate with global partners to develop shared standards, guidelines, or regulations that recognize the need for diverse perspectives and safeguards in AI development.\n",
      "\n",
      "Considerations of current legal frameworks:\n",
      "\n",
      "1. **Update existing laws**: Update existing laws and regulations to address emerging issues related to autonomous AI systems, taking into account international human rights instruments and technological advancements.\n",
      "2. **New legislation**: Ensure that new laws and regulations can be adapted as technology evolves, creating flexible legislation for future-proofing the governance of AI.\n",
      "3. **International harmonization efforts**: Join international efforts to develop and promote the convergence of national standards and best practices in AI governance to facilitate smoother implementation, exchange, and comparison across jurisdictions.\n",
      "4. **Transparency and explainability**: Ensure transparent decision-making processes and techniques like model interpretability are used as much as possible, making it easier for stakeholders to validate or dispute findings.\n",
      "\n",
      "Given these considerations and steps toward reconciliation:\n",
      "\n",
      "1. Encourage diverse participation in ethical decision-making.\n",
      "2. Inclusive governance to recognize the broader consequences of AI technologies can effectively improve societal coordination of technological innovations.\n",
      "3. Addressing current legal limitations demands an ongoing effort through international research collaboration, policy consultation, updates, or harmonization.\n",
      "\n",
      "**By adopting these perspectives and strategies, we will ensure a brighter future for society's use of AI systems that make life-altering decisions while addressing our existing challenges related to diverse cultural perspectives and regulatory limits in their development.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(together)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "judge = f\"\"\"You are judging a competition between {len(competitors)} competitors.\n",
    "Each model has been given this question:\n",
    "\n",
    "{question}\n",
    "\n",
    "Your job is to evaluate each response for clarity and strength of argument, and rank them in order of best to worst.\n",
    "Respond with JSON, and only JSON, with the following format:\n",
    "{{\"results\": [\"best competitor number\", \"second best competitor number\", \"third best competitor number\", ...]}}\n",
    "\n",
    "Here are the responses from each competitor:\n",
    "\n",
    "{together}\n",
    "\n",
    "Now respond with the JSON with the ranked order of the competitors, nothing else. Do not include markdown formatting or code blocks.\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are judging a competition between 2 competitors.\n",
      "Each model has been given this question:\n",
      "\n",
      "How would you reconcile the ethical implications of creating autonomous AI systems capable of making life-altering decisions with the potential benefits they offer, while considering diverse cultural perspectives and the limitations of current legal frameworks?\n",
      "\n",
      "Your job is to evaluate each response for clarity and strength of argument, and rank them in order of best to worst.\n",
      "Respond with JSON, and only JSON, with the following format:\n",
      "{\"results\": [\"best competitor number\", \"second best competitor number\", \"third best competitor number\", ...]}\n",
      "\n",
      "Here are the responses from each competitor:\n",
      "\n",
      "# Response from competitor 1\n",
      "\n",
      "Reconciling the ethical implications of autonomous AI systems that make life-altering decisions with their potential benefits, especially while respecting diverse cultural perspectives and navigating current legal limitations, requires a multi-faceted, inclusive, and adaptive approach. Here's a structured way to think about it:\n",
      "\n",
      "### 1. **Recognize the Ethical Stakes and Potential Benefits**\n",
      "- **Ethical Stakes:** Autonomous AI making decisions—such as in healthcare, criminal justice, or finance—can profoundly affect individuals’ rights, dignity, and well-being. Risks include bias, loss of accountability, and erosion of human agency.\n",
      "- **Potential Benefits:** Improved efficiency, consistency, scalability of decision-making, access to expertise, and even the ability to mitigate human biases when carefully designed.\n",
      "\n",
      "### 2. **Adopt a Human-Centered Ethical Framework**\n",
      "- **Prioritize Human Rights and Dignity:** Ensure AI decision-making respects fundamental human rights (privacy, fairness, autonomy).\n",
      "- **Accountability and Transparency:** AI’s decisions should be explainable to affected individuals, with clear accountability channels.\n",
      "- **Informed Consent and Control:** Where possible, individuals should retain control over decisions or have the right to contest AI outcomes.\n",
      "\n",
      "### 3. **Incorporate Diverse Cultural Perspectives**\n",
      "- **Multicultural Ethical Engagement:** Different societies have varying values related to autonomy, collective good, and justice. Engage ethicists, social scientists, and stakeholders globally to incorporate a multiplicity of values.\n",
      "- **Contextual Adaptation:** AI systems and policies should be adaptable to cultural norms without enforcing homogenized standards that might marginalize local practices.\n",
      "- **Participatory Design:** Include representatives from different cultural backgrounds in the design and evaluation of AI systems.\n",
      "\n",
      "### 4. **Address Legal Framework Limitations with Proactive Governance**\n",
      "- **Iterative Policy Development:** Laws often lag behind technology. Regulators should adopt flexible, adaptive approaches such as regulatory sandboxes to test AI impacts safely.\n",
      "- **International Cooperation:** Foster international norms and agreements to manage AI’s cross-border implications and reduce regulatory arbitrage.\n",
      "- **Embedding Ethics in Design:** Encourage or mandate “ethics-by-design” principles where AI developers embed ethical considerations throughout the lifecycle of AI systems.\n",
      "\n",
      "### 5. **Foster Multistakeholder Collaboration**\n",
      "- Collaboration between AI developers, ethicists, policymakers, civil society, and affected communities is crucial to balance competing interests and values.\n",
      "- Establish independent oversight bodies with diverse representation to audit and guide AI deployment.\n",
      "\n",
      "### 6. **Promote Education and Awareness**\n",
      "- Equip users and the public with knowledge to understand AI’s capabilities and limitations, empowering them to engage critically and advocate for their rights.\n",
      "\n",
      "---\n",
      "\n",
      "### Summary\n",
      "Balancing the ethical challenges of autonomous AI in life-altering decisions with its benefits requires a human-centric, culturally sensitive, and legally adaptive approach. This means embedding ethical principles and transparency, respecting cultural diversity, advancing inclusive governance structures, and proactively evolving legal frameworks to keep pace with technological sophistication. The goal is not to reject AI but to shape its development and use so that it aligns with broadly shared human values and safeguards individual rights.\n",
      "\n",
      "# Response from competitor 2\n",
      "\n",
      "Reconciling the ethical implications of creating autonomous AI systems that can make life-altering decisions is a complex challenge that requires consideration of various factors, including diversity of cultural perspectives and limitations of current legal frameworks. Here are some steps to address these concerns:\n",
      "\n",
      "1. **Diverse stakeholder engagement**: Involve diverse stakeholders, including policymakers, ethicists, technologists, industry experts, and members from different cultural backgrounds, in the development process to ensure that ethics and values are integrated at each stage.\n",
      "2. **Value alignment**: Conduct thorough value-alignment studies to identify and prioritize ethical principles, such as fairness, transparency, accountability, and human dignity, that must be incorporated into AI decision-making processes.\n",
      "3. **Regulatory frameworks**: Collaborate with policymakers and regulatory bodies to develop and update frameworks that account for the societal implications of autonomous AI systems. Encourage a multidisciplinary approach to ensure effectiveness in addressing ethical concerns.\n",
      "4. **Human oversight and accountability**: Ensure that human oversight and accountability are inherent features of autonomous AI systems, allowing for intervention or review of decisions made by the system whenever necessary.\n",
      "5. **Cultural sensitivity training**: Provide cultural sensitivity training for developers and users of autonomous AI systems to recognize and respect diverse cultural perspectives and values embedded in these systems.\n",
      "6. **Regular evaluation and assessment**: Regularly evaluate and assess the impact of autonomous AI systems on society, addressing concerns raised by diverse stakeholders and updating ethical frameworks as needed.\n",
      "7. **Addressing bias and fairness**: Incorporate approaches to detect and mitigate bias into AI decision-making processes, ensuring that they are fair, transparent, and respect human diversity.\n",
      "8. **Global cooperation and collaboration**: Collaborate with global partners to develop shared standards, guidelines, or regulations that recognize the need for diverse perspectives and safeguards in AI development.\n",
      "\n",
      "Considerations of current legal frameworks:\n",
      "\n",
      "1. **Update existing laws**: Update existing laws and regulations to address emerging issues related to autonomous AI systems, taking into account international human rights instruments and technological advancements.\n",
      "2. **New legislation**: Ensure that new laws and regulations can be adapted as technology evolves, creating flexible legislation for future-proofing the governance of AI.\n",
      "3. **International harmonization efforts**: Join international efforts to develop and promote the convergence of national standards and best practices in AI governance to facilitate smoother implementation, exchange, and comparison across jurisdictions.\n",
      "4. **Transparency and explainability**: Ensure transparent decision-making processes and techniques like model interpretability are used as much as possible, making it easier for stakeholders to validate or dispute findings.\n",
      "\n",
      "Given these considerations and steps toward reconciliation:\n",
      "\n",
      "1. Encourage diverse participation in ethical decision-making.\n",
      "2. Inclusive governance to recognize the broader consequences of AI technologies can effectively improve societal coordination of technological innovations.\n",
      "3. Addressing current legal limitations demands an ongoing effort through international research collaboration, policy consultation, updates, or harmonization.\n",
      "\n",
      "**By adopting these perspectives and strategies, we will ensure a brighter future for society's use of AI systems that make life-altering decisions while addressing our existing challenges related to diverse cultural perspectives and regulatory limits in their development.\n",
      "\n",
      "\n",
      "\n",
      "Now respond with the JSON with the ranked order of the competitors, nothing else. Do not include markdown formatting or code blocks.\n"
     ]
    }
   ],
   "source": [
    "print(judge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "judge_messages = [{\"role\": \"user\", \"content\": judge}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"results\": [\"1\", \"2\"]}\n"
     ]
    }
   ],
   "source": [
    "# Judgement time!\n",
    "\n",
    "response = openai.chat.completions.create(\n",
    "    model=\"o3-mini\",\n",
    "    messages=judge_messages,\n",
    ")\n",
    "results = response.choices[0].message.content\n",
    "print(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rank 1: gpt-4.1-mini\n",
      "Rank 2: llama3.2\n"
     ]
    }
   ],
   "source": [
    "# OK let's turn this into results!\n",
    "\n",
    "results_dict = json.loads(results)\n",
    "ranks = results_dict[\"results\"]\n",
    "for index, result in enumerate(ranks):\n",
    "    competitor = competitors[int(result)-1]\n",
    "    print(f\"Rank {index+1}: {competitor}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table style=\"margin: 0; text-align: left; width:100%\">\n",
    "    <tr>\n",
    "        <td style=\"width: 150px; height: 150px; vertical-align: middle;\">\n",
    "            <img src=\"../assets/exercise.png\" width=\"150\" height=\"150\" style=\"display: block;\" />\n",
    "        </td>\n",
    "        <td>\n",
    "            <h2 style=\"color:#ff7800;\">Exercise</h2>\n",
    "            <span style=\"color:#ff7800;\">Which pattern(s) did this use? Try updating this to add another Agentic design pattern.\n",
    "            </span>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table style=\"margin: 0; text-align: left; width:100%\">\n",
    "    <tr>\n",
    "        <td style=\"width: 150px; height: 150px; vertical-align: middle;\">\n",
    "            <img src=\"../assets/business.png\" width=\"150\" height=\"150\" style=\"display: block;\" />\n",
    "        </td>\n",
    "        <td>\n",
    "            <h2 style=\"color:#00bfff;\">Commercial implications</h2>\n",
    "            <span style=\"color:#00bfff;\">These kinds of patterns - to send a task to multiple models, and evaluate results,\n",
    "            and common where you need to improve the quality of your LLM response. This approach can be universally applied\n",
    "            to business projects where accuracy is critical.\n",
    "            </span>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
