{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d3eefafc",
   "metadata": {},
   "source": [
    "# Day 4 - Comparing AI Agent Frameworks: Simplicity vs Power in LLM Orchestration\n",
    "\n",
    "### Summary\n",
    "This lecture introduces the landscape of Agentic AI frameworks, categorizing them by complexity and discussing their respective pros and cons to prepare students for building sophisticated LLM-powered applications. It outlines a spectrum from direct LLM API interaction (no framework approach, favored for control and transparency) and the Model Context Protocol (MCP), through lightweight options like OpenAI Agents SDK (noted for simplicity and flexibility) and CrewAI (highlighted for its low-code YAML configuration), up to powerful but more complex ecosystems such as LangGraph and Autogen (which offer extensive capabilities but steeper learning curves and deeper ecosystem commitment). The course aims to cover these representative options, starting with direct API use, to equip data science professionals with the discernment needed to select the most appropriate framework for their specific project requirements, team skills, and desired balance between control and abstraction.\n",
    "\n",
    "---\n",
    "### Highlights\n",
    "-   **Overview of Agentic AI Frameworks:** The session introduces Agentic AI frameworks as tools that provide abstraction layers and \"glue code\" to streamline the development of LLM-based agentic solutions, enabling developers to concentrate on solving specific business problems rather than low-level LLM interaction details.\n",
    "-   **No Framework/Direct API Approach:** This foundational approach involves connecting directly to LLM APIs, offering maximum control over prompts and a clear understanding of the underlying mechanics. The course will initially adopt this method, aligning with philosophies like Anthropic's that advocate for direct interaction for clarity and precision.\n",
    "-   **Model Context Protocol (MCP):** Presented not as a framework but as an open-source protocol initiated by Anthropic. MCP aims to standardize how LLMs connect with external data sources and tools, promoting interoperability and reducing the need for custom integration code by ensuring all components adhere to a common protocol.\n",
    "-   **Lightweight and Flexible Frameworks:**\n",
    "    -   **OpenAI Agents SDK:** Highlighted as a highly favored, very new, lightweight, simple, and flexible option that the course will cover. Its newness means its API can be subject to rapid changes.\n",
    "    -   **CrewAI:** Another preferred framework, known for its ease of use and relatively lightweight nature. A key feature is its \"low-code\" aspect, allowing for agent and task configuration primarily through YAML files.\n",
    "-   **Powerful but Complex Ecosystems:**\n",
    "    -   **LangGraph:** Developed by the creators of Langchain, this framework is described as powerful but with a steeper learning curve. It enables building sophisticated computational graphs of agents and tools, but requires significant buy-in to its extensive terminology and abstractions.\n",
    "    -   **Autogen (from Microsoft):** Similar to LangGraph in being relatively heavyweight and offering substantial power at the cost of a more involved learning process. Using Autogen means deeply engaging with its specific ecosystem.\n",
    "-   **Rationale for Framework Choice:** The selection of an appropriate agentic framework is multifaceted, depending on the specific use case, desired business outcomes, and a team's or individual's preference concerning the trade-offs between direct control, simplicity, speed of development, and the comprehensive power offered by more extensive ecosystems.\n",
    "-   **Course Trajectory and Learning Objectives:** The course is structured to guide students through a representative range of these frameworks—from direct API use to lightweight SDKs and finally to more complex systems. This progression is designed to provide a practical understanding that empowers data science professionals to make informed decisions when selecting tools for their own agentic AI projects.\n",
    "-   **Instructor's Perspective:** While acknowledging a personal preference for simpler, lightweight frameworks that offer flexibility and stay \"out of the way,\" the instructor affirms the value and power of the more complex ecosystems and commits to providing a balanced exploration of all covered options.\n",
    "\n",
    "---\n",
    "### Conceptual Understanding\n",
    "-   **Agentic AI Frameworks**\n",
    "    1.  **Why is this concept important?** Agentic AI frameworks provide structured environments, pre-built components, and abstractions that significantly simplify the development of complex applications where AI agents (typically powered by LLMs) can perceive, reason, plan, and act to achieve goals. They manage boilerplate code for LLM interactions, tool usage, memory, and multi-agent coordination, allowing developers to focus on higher-level logic.\n",
    "    2.  **How does it connect to real-world tasks, problems, or applications?** These frameworks are instrumental in building sophisticated applications such as autonomous research assistants that can browse the web and synthesize information, AI-powered project managers that can delegate tasks to other agents or tools, personalized tutors, or complex data analysis systems that can autonomously execute code and interpret results.\n",
    "    3.  **Which related techniques or areas should be studied alongside this concept?** LLM orchestration, tool integration patterns for LLMs, multi-agent systems theory, prompt engineering for agent control, state management in conversational AI, and software development kits (SDKs) and API design principles.\n",
    "\n",
    "-   **Model Context Protocol (MCP)**\n",
    "    1.  **Why is this concept important?** MCP, proposed by Anthropic, aims to establish an open-source, standardized protocol for how LLMs should interact with external tools and data sources. The goal is to enable seamless, \"plug-and-play\" interoperability between different models and tools without requiring custom integration code for each pair, thereby fostering a more open and modular AI ecosystem.\n",
    "    2.  **How does it connect to real-world tasks, problems, or applications?** If widely adopted, MCP could simplify the development of agentic systems by allowing data scientists to easily swap out LLMs or tools from different providers, as long as they all conform to the protocol. This could reduce vendor lock-in and accelerate innovation by making it easier to combine best-of-breed components.\n",
    "    3.  **Which related techniques or areas should be studied alongside this concept?** Open standards development, API design best practices, interoperability challenges in distributed systems, data exchange formats (like JSON, XML), and the philosophical differences between open protocols and proprietary frameworks.\n",
    "\n",
    "-   **Low-Code Angle in Agentic Frameworks (e.g., CrewAI with YAML)**\n",
    "    1.  **Why is this concept important?** Incorporating low-code approaches, such as using YAML or JSON for configuring agent behaviors, tasks, and tool access (as seen in CrewAI), makes the development of agentic systems more accessible. It allows developers, and potentially even individuals with less coding expertise, to define and modify complex agent workflows through declarative configuration files rather than extensive programming.\n",
    "    2.  **How does it connect to real-world tasks, problems, or applications?** This is beneficial for rapid prototyping of agentic applications, enabling subject matter experts to contribute more directly to agent design, simplifying the management of multiple agent configurations, and potentially lowering the barrier to entry for creating sophisticated multi-agent systems.\n",
    "    3.  **Which related techniques or areas should be studied alongside this concept?** Declarative programming paradigms, configuration-as-code principles, data serialization languages (YAML, JSON), no-code/low-code development platforms, and visual programming interfaces as potential extensions.\n",
    "\n",
    "---\n",
    "### Reflective Questions\n",
    "1.  **Application:** Given the spectrum from direct API use (maximum control) to heavyweight frameworks like LangGraph (maximum built-in power/structure), which approach would be most suitable for a large enterprise looking to build a standardized, auditable, and highly complex internal knowledge management agent that needs to integrate with dozens of legacy systems? Provide a one-sentence explanation.\n",
    "    * *Answer:* A large enterprise might lean towards a more heavyweight framework like LangGraph or Autogen, despite the learning curve, because these frameworks often offer robust structures for managing complexity, ensuring auditable workflows through their graph-based nature, and potentially better support for integrating numerous, diverse tools needed for legacy systems.\n",
    "2.  **Teaching:** How would you explain the core benefit of the \"Model Context Protocol (MCP)\" to a junior colleague who is currently writing a lot of custom \"glue code\" to make their chosen LLM use a new third-party API tool, using an analogy?\n",
    "    * *Answer:* \"Imagine if every USB device (like a mouse or keyboard) needed custom software just to talk to your computer; MCP is like trying to create a universal USB standard for AI tools, so your LLM could 'plug and play' with any MCP-compliant tool without you writing all that specific glue code each time.\"\n",
    "3.  **Extension:** The talk mentions a personal bias towards \"lightweight, simple, and flexible\" frameworks that \"stay out of your way.\" What potential long-term maintenance challenges or scalability limitations might arise if one *exclusively* relies on such lightweight frameworks or direct API calls for very large and evolving agentic systems, and why?\n",
    "    * *Answer:* Exclusively using lightweight frameworks or direct API calls for very large, evolving systems might lead to increased maintenance burdens due to managing a lot of custom-built orchestration logic, potential inconsistencies across different parts of the system if not carefully managed, and challenges in onboarding new developers who need to understand a bespoke architecture rather than a standardized framework's conventions, potentially impacting scalability of development effort.\n",
    "\n",
    "# Day 4 - Resources vs. Tools: Two Ways to Enhance LLM Capabilities in Agentic AI\n",
    "\n",
    "### Summary\n",
    "This lecture introduces two pivotal concepts for augmenting Large Language Model (LLM) capabilities: \"resources\" and \"tools.\" Resources enhance LLM expertise by directly incorporating relevant contextual data into prompts, a technique that can be advanced through methods like Retrieval Augmented Generation (RAG) for dynamic context retrieval. \"Tools,\" on the other hand, grant LLMs a form of supervised autonomy by enabling them to request the execution of specific actions (e.g., database queries, API calls); this is demystified as a structured process where the LLM outputs a JSON request that the developer's code then interprets and acts upon, rather than the LLM directly executing actions. Although the mechanics of tool use are detailed, the immediate lab session will focus on applying resources, with practical tool implementation scheduled for the subsequent session.\n",
    "\n",
    "---\n",
    "### Highlights\n",
    "-   **Concept of \"Resources\" for Enhancing LLMs:** Resources are defined as contextual information or data provided to an LLM within its prompt to improve its expertise and the relevance of its responses. This is a fundamental technique for tailoring LLM outputs to specific domains or knowledge bases.\n",
    "-   **Retrieval Augmented Generation (RAG) as an Advanced Resource Strategy:** While basic resource provision involves manually \"stuffing\" data into prompts, RAG represents a more sophisticated approach. RAG systems dynamically retrieve and inject only the most pertinent information from a larger corpus in response to a query, optimizing context and relevance.\n",
    "-   **Defining \"Tools\" for LLM Action-Taking:** Tools extend LLM capabilities beyond text generation by allowing them to request that specific, predefined actions be performed. This enables LLMs to interact with external systems or data, forming a cornerstone of agentic AI and granting them a degree of operational autonomy.\n",
    "-   **Demystification of LLM Tool Use (Function Calling):** The lecture clarifies a common misconception: LLMs do not directly execute tools or external code. Instead, the process involves:\n",
    "    1.  The developer describing available tools to the LLM within the prompt.\n",
    "    2.  The LLM, if it decides a tool is needed, responds with a structured output (typically JSON) specifying the tool to use and its parameters.\n",
    "    3.  The developer's application code parses this JSON request.\n",
    "    4.  The application code then executes the actual tool/function locally or calls the relevant API.\n",
    "    5.  The result from the tool execution is then fed back to the LLM in a subsequent prompt, allowing it to formulate a final, informed response.\n",
    "-   **The Role of JSON in Tool Communication:** The structured JSON output from an LLM requesting a tool action is critical. It provides a standardized, machine-readable format for your code to understand which tool the LLM wants to use and with what specific inputs.\n",
    "-   **Two-Step (or Multi-Step) LLM Interaction for Tool Use:** Implementing tool use typically requires at least two calls to the LLM: an initial call where the LLM might request a tool, and a subsequent call after your code has executed the tool and has a result to share back with the LLM.\n",
    "-   **LLM \"Autonomy\" in Tool Selection:** The apparent autonomy of the LLM lies in its capacity to analyze a user's query and, based on the descriptions of available tools, decide *if* and *which* tool's execution it should request to best address the query.\n",
    "-   **Immediate Lab Focus on Resources:** Despite the in-depth explanation of how tools function, the practical lab session for the current day will concentrate on implementing and utilizing \"resources.\" The hands-on application of \"tools\" is deferred to the next lab session.\n",
    "\n",
    "---\n",
    "### Conceptual Understanding\n",
    "-   **Resources (in LLM context) & Prompt Augmentation**\n",
    "    1.  **Why is this concept important?** Providing LLMs with \"resources\"—relevant data, documents, or contextual information—directly within their prompt is a fundamental technique to ground their responses in specific, factual information. This significantly improves the accuracy, relevance, and utility of LLM outputs, especially for queries requiring knowledge outside their general training data.\n",
    "    2.  **How does it connect to real-world tasks, problems, or applications?** This is used extensively in building specialized AI assistants, such as customer support bots equipped with product manuals, Q&A systems that can query private document repositories, or any scenario where an LLM needs to access and use specific, up-to-date, or proprietary information to perform its task effectively.\n",
    "    3.  **Which related techniques or areas should be studied alongside this concept?** Retrieval Augmented Generation (RAG), in-context learning, prompt engineering, management of LLM context window limitations, and vector databases for storing and retrieving contextual data.\n",
    "\n",
    "-   **Retrieval Augmented Generation (RAG)**\n",
    "    1.  **Why is this concept important?** RAG is an advanced architectural pattern for providing resources to LLMs. Instead of manually inserting all potentially relevant information into a prompt (which is often infeasible due to context window limits), RAG systems first use a retrieval mechanism (commonly semantic search over a vector database) to find the most relevant snippets of information from a large knowledge corpus based on the user's query. These highly relevant snippets are then \"augmented\" into the LLM's prompt.\n",
    "    2.  **How does it connect to real-world tasks, problems, or applications?** RAG is crucial for building applications that require LLMs to answer questions based on vast, dynamic, or private document sets, such as enterprise knowledge bases, research paper databases, or up-to-date news archives. It helps ensure factual consistency, reduces hallucination, and allows LLMs to cite sources.\n",
    "    3.  **Which related techniques or areas should be studied alongside this concept?** Vector embeddings, vector databases (e.g., Pinecone, Weaviate, Chroma), semantic search algorithms, information retrieval theory, document chunking strategies, and evaluating the quality of retrieved context.\n",
    "\n",
    "-   **LLM Tool Use / Function Calling (The Mechanism)**\n",
    "    1.  **Why is this concept important?** Tool use (often referred to as \"function calling\" in APIs like OpenAI's) is the mechanism that enables LLMs to interact with the external world, execute computations, or access live data, moving beyond simple text generation. The \"trick\" is that the LLM doesn't execute the tool directly; it generates a structured data output (usually JSON) that precisely describes which function your code should call and with what arguments. Your code then executes this function and passes the result back to the LLM.\n",
    "    2.  **How does it connect to real-world tasks, problems, or applications?** This allows LLMs to perform a vast array of practical actions: querying databases for real-time information, making API calls to services like weather forecasts or flight booking systems, running data analysis code, interacting with software applications, or even controlling smart home devices. It's fundamental to building capable AI agents.\n",
    "    3.  **Which related techniques or areas should be studied alongside this concept?** API design and integration, JSON schema definition (for describing tools to the LLM), robust error handling for external calls, security considerations when allowing LLM-triggered actions, state management in multi-step agentic workflows, and designing effective prompts that clearly describe tool functionality to the LLM.\n",
    "\n",
    "---\n",
    "### Reflective Questions\n",
    "1.  **Application:** The lecture contrasts manually \"stuffing\" resources into a prompt versus using a RAG system. For a project that needs to build an LLM-based assistant to help software developers navigate a very large and constantly updated internal codebase and documentation, which method for providing \"resources\" would be more scalable and maintainable, and why?\n",
    "    * *Answer:* A RAG system would be far more scalable and maintainable because it can dynamically retrieve only the relevant code snippets or documentation sections from the vast, changing codebase based on the developer's query, avoiding the impracticality of stuffing an entire, ever-evolving codebase into a limited prompt window and ensuring up-to-date information.\n",
    "2.  **Teaching:** How would you explain the core difference between an LLM simply *generating text about performing an action* versus an LLM *using a tool* (as demystified in the lecture) to a non-technical stakeholder, using a simple analogy?\n",
    "    * *Answer:* \"Imagine asking a consultant for advice: generating text is like them just *telling* you, 'You should check your sales database.' Using a tool is like them saying, 'Okay, I need to check the sales database. Can you (your system) run a query for Q3 sales for Product X and tell me the result?' Then, after your system gets that number, they use it to give you a specific answer.\"\n",
    "3.  **Extension:** The lecture explains that LLM tool use involves your code executing an action based on the LLM's JSON request. What security implications should a developer be acutely aware of when designing the system that interprets the LLM's tool requests and executes corresponding functions, especially if those tools can modify data or interact with external services?\n",
    "    * *Answer:* Developers must be acutely aware of potential injection attacks (where the LLM might generate malicious parameters for a tool), ensuring strict input validation and sanitization for all parameters passed to tools, implementing the principle of least privilege for tool capabilities, authenticating and authorizing all actions, and having robust logging and monitoring to detect any unintended or malicious tool usage triggered by the LLM.\n",
    "\n",
    "# Day 4 - Build a Web Chatbot That Acts Like You Using Gradio & OpenAI\n",
    "\n",
    "### Summary\n",
    "This lab session focuses on creating a personalized chatbot that acts as a digital representation of the user by leveraging \"resources\"—specifically, text extracted from the user's LinkedIn PDF profile and a brief summary text file. The process involves using the `PyPDF2` library to parse the PDF content, meticulously crafting a system prompt for an LLM (`gpt-4o-mini`) that embeds this personal data to define the chatbot's persona and knowledge base, and then deploying an interactive chat interface using the `gradio` library. The resulting application allows users to converse with an AI that responds as if it were the individual whose information was provided, effectively demonstrating how resource augmentation can create tailored and knowledgeable LLM agents for tasks like answering career-related queries.\n",
    "\n",
    "---\n",
    "### Highlights\n",
    "-   **Personalized Chatbot using \"Resources\":** The central aim of the lab is to build a chatbot that can impersonate the user by incorporating personal information—derived from their LinkedIn profile (as a PDF) and a short summary text—directly into the LLM's system prompt. This allows the chatbot to answer questions about the user's career, skills, and experience with context.\n",
    "-   **PDF Text Extraction with `PyPDF2`:** The lab demonstrates the use of the `PyPDF2` library to programmatically read and extract text content from PDF files. This is a crucial step for making information from common document formats like resumes or profiles accessible as resources for LLMs.\n",
    "-   **Crafting a Detailed System Prompt:** A key element is the construction of a comprehensive system prompt for the `gpt-4o-mini` LLM. This prompt explicitly instructs the LLM on its persona (to act as the user, by name), its role (e.g., answering questions on a personal website), the desired tone (professional, engaging), and how to handle queries where information is lacking (\"if you don't know the answer, say so\"). The extracted LinkedIn text and summary are embedded within this prompt using markdown-style headings for structure.\n",
    "-   **Rapid UI Development with `gradio`:** The `gradio` library is introduced as a tool for quickly creating interactive web-based user interfaces for machine learning applications, including LLM-powered chatbots. This enables data scientists to build functional demos without needing extensive front-end development skills.\n",
    "-   **Gradio Callback Function for LLM Interaction:** The logic for the chatbot is encapsulated in a Python function (named `chat` in the lab) that Gradio calls when a user sends a message. This function is responsible for:\n",
    "    1.  Assembling the full message list for the LLM (system prompt, chat history, current user message).\n",
    "    2.  Calling the OpenAI API.\n",
    "    3.  Returning the LLM's textual response to the Gradio interface.\n",
    "-   **Maintaining Conversational History:** The `gradio.ChatInterface` automatically handles the chat history, passing it to the callback function with each new user message. This allows the LLM to maintain context across multiple turns in a conversation, leading to more coherent interactions.\n",
    "-   **Practical Application: Building a \"Professional Avatar\":** The lab culminates in a functional chatbot that can act as a \"professional avatar\" or \"alter ego\" of the user, capable of responding to queries based on the provided personal documents. This showcases a tangible real-world application of resource-augmented LLMs for tasks like personal branding or automated professional Q&A.\n",
    "-   **Personalization as a Core Student Task:** Students are explicitly guided to replace the instructor's sample documents with their own LinkedIn profile/resume and summary. This direct personalization makes the learning experience more engaging and immediately applicable.\n",
    "-   **Foundational Step for Tool Use:** Although this lab focuses entirely on using \"resources,\" it is framed as laying essential groundwork for the subsequent introduction of \"tools,\" emphasizing that providing context is a precursor to enabling LLMs to take actions.\n",
    "\n",
    "---\n",
    "### Conceptual Understanding\n",
    "-   **`PyPDF2` (PDF Parsing Library)**\n",
    "    1.  **Why is this concept important?** `PyPDF2` is a Python library that enables developers to read, extract text and metadata from, and perform other manipulations on PDF files (though it primarily excels with text-based PDFs rather than scanned images). Since PDFs are a ubiquitous format for documents like resumes, reports, and academic papers, libraries like `PyPDF2` are essential for accessing their content programmatically.\n",
    "    2.  **How does it connect to real-world tasks, problems, or applications?** In data science, it's vital for any workflow that involves ingesting information from PDF documents. This includes building Retrieval Augmented Generation (RAG) systems over a corpus of research papers, extracting structured data from PDF invoices or forms, or, as in this lab, making the textual content of a LinkedIn profile or resume available as a contextual resource for an LLM.\n",
    "    3.  **Which related techniques or areas should be studied alongside this concept?** Text extraction algorithms, other PDF parsing libraries (e.g., `pdfplumber`, `pymupdf` which handles images and complex layouts better), Optical Character Recognition (OCR) for image-based PDFs, document chunking strategies, and general file input/output operations in Python.\n",
    "\n",
    "-   **`gradio` (UI Library for Data Science Applications)**\n",
    "    1.  **Why is this concept important?** `gradio` is a Python library designed to help data scientists and machine learning engineers quickly create intuitive and interactive web-based user interfaces for their models and data applications. It abstracts away much of the complexity of web development, providing simple APIs to build demos with various input/output components (e.g., text boxes, image uploads, chat windows).\n",
    "    2.  **How does it connect to real-world tasks, problems, or applications?** `gradio` is widely used for creating shareable demos of machine learning models (including LLMs), building simple internal tools for model testing or data exploration, rapidly prototyping AI-powered applications, and making complex models accessible to non-technical users for feedback or operational use. In this lab, it provides the chat interface for the personalized LLM.\n",
    "    3.  **Which related techniques or areas should be studied alongside this concept?** Basic principles of web application architecture (client-server), UI/UX design fundamentals, other Python web frameworks (like Flask or Streamlit, for comparison), and methods for deploying Python web applications.\n",
    "\n",
    "-   **System Prompts vs. User Prompts in LLM Interaction**\n",
    "    1.  **Why is this concept important?** Distinguishing between system prompts and user prompts is a key technique in prompt engineering for controlling and guiding LLM behavior more effectively.\n",
    "        -   **System Prompt:** This initial prompt sets the overarching context, instructions, persona, constraints, and any background knowledge the LLM should consistently adhere to throughout an entire conversational session. It's akin to giving an actor their role, script guidelines, and backstory.\n",
    "        -   **User Prompt:** This represents the specific question, command, or input provided by the end-user during a particular turn in the conversation.\n",
    "    2.  **How does it connect to real-world tasks, problems, or applications?** This separation is crucial for building robust, predictable, and steerable LLM applications. The system prompt defines *how* an AI assistant should behave (e.g., \"You are a helpful financial advisor specializing in retirement planning\"), what specific knowledge it should draw upon (as in this lab, where personal documents are embedded as resources), and the desired style or format of its responses. User prompts then drive the specific turn-by-turn interaction within that defined framework.\n",
    "    3.  **Which related techniques or areas should be studied alongside this concept?** Advanced prompt engineering techniques, persona crafting for AI agents, instructional design for prompts, managing conversational context and history, and few-shot prompting within the system message.\n",
    "\n",
    "---\n",
    "### Reflective Questions\n",
    "1.  **Application:** The lab constructs a chatbot persona from a LinkedIn PDF. What other specific type of document could be used as a primary \"resource\" to create a highly specialized AI assistant for a particular business function, and what would that function be?\n",
    "    * *Answer:* A company's internal Standard Operating Procedures (SOPs) manual could be used as a primary resource to create a highly specialized AI assistant that helps new employees understand and correctly follow complex internal processes for tasks like expense reporting or project setup.\n",
    "2.  **Teaching:** How would you explain the role of the `chat` function (the Gradio callback) to a colleague who understands basic Python but is new to web interfaces or event-driven programming, using a simple analogy?\n",
    "    * *Answer:* \"Think of the Gradio chat window as a customer service desk. The `chat` function is like the agent sitting behind the desk; whenever a customer (user) types a message and hits 'send,' Gradio (the system) hands that message and the conversation so far to our `chat` agent, who then figures out the reply (by calling the LLM) and hands it back to Gradio to display to the customer.\"\n",
    "3.  **Extension:** The system prompt in this lab embeds the full text of the LinkedIn profile. If this text were very long, potentially exceeding the LLM's context window, what strategy could be implemented *within the `chat` callback function itself* (before calling the LLM) to mitigate this, drawing inspiration from RAG principles?\n",
    "    * *Answer:* Within the `chat` callback function, before calling the main LLM, one could implement a mini-retrieval step: use the current user `message` to perform a semantic search (e.g., using sentence embeddings) against pre-chunked segments of the long LinkedIn profile text, select only the top 1-3 most relevant chunks, and then dynamically construct the system prompt or augment the user prompt with only these highly relevant chunks, rather than the entire document.\n",
    "\n",
    "# Day 4 - Using Gemini to Evaluate GPT-4 Responses: A Multi-LLM Pipeline\n",
    "\n",
    "### Summary\n",
    "This advanced lab session meticulously constructs a complete \"Evaluator-Optimizer\" agentic workflow by directly orchestrating Large Language Model (LLM) API calls, deliberately avoiding formal agentic frameworks to provide deeper insight into their mechanics. The system employs a primary LLM (`gpt-4o-mini`) to generate answers to user queries based on previously established \"resources\" (personal information). A second LLM (Google's Gemini Flash) then acts as an evaluator, leveraging \"structured outputs\" defined by Pydantic models to assess the primary LLM's response for acceptability and provide feedback. If a response is deemed unsatisfactory, the primary LLM is triggered to re-attempt the answer, this time incorporating the evaluator's specific feedback, with the entire interaction seamlessly managed within a Gradio-powered chat interface, thus demonstrating a practical, framework-less method for building self-correcting and higher-quality AI systems.\n",
    "\n",
    "---\n",
    "### Highlights\n",
    "-   **Framework-less Evaluator-Optimizer Workflow Implementation:** The core achievement of this lab is the successful construction of a sophisticated agentic pattern—where one LLM evaluates and provides feedback to another for iterative improvement—entirely through direct LLM API calls. This approach bypasses formal agentic frameworks, offering students a transparent understanding of the fundamental interactions involved.\n",
    "-   **Pydantic for Defining Data Schemas:** The `pydantic` library is introduced and utilized to create a well-defined data structure (an `Evaluation` class inheriting from `BaseModel`, with fields `is_acceptable: bool` and `feedback: str`). This schema dictates the format for the evaluator LLM's assessment, ensuring its output is consistent and programmatically usable.\n",
    "-   **Leveraging Structured Outputs with LLMs (Gemini Example):** A key technique showcased is \"structured outputs.\" The evaluator LLM (Gemini Flash) is specifically instructed to format its response according to the predefined `Evaluation` Pydantic model. The underlying LLM client library then automatically parses the LLM's native JSON output into a Python `Evaluation` object, greatly simplifying the process of extracting structured data from the LLM.\n",
    "-   **Dual LLM System Architecture (Generator & Evaluator):**\n",
    "    -   **Generator LLM (`gpt-4o-mini`):** This model is responsible for generating the initial user-facing responses, drawing upon the \"resources\" (user's LinkedIn profile and summary) established in the previous lab segment.\n",
    "    -   **Evaluator LLM (Gemini Flash):** This model's role is to critically assess the generator's output. It receives its own system prompt, which includes the same contextual resources as the generator, along with instructions to evaluate the professionalism and appropriateness of the response.\n",
    "-   **Conditional Re-run Mechanism with Feedback Loop:** If the evaluator LLM (Gemini) determines that the initial response from the generator LLM (`gpt-4o-mini`) is unacceptable (e.g., `evaluation.is_acceptable == False`), the system automatically triggers a second call to the generator. Crucially, the prompt for this re-run is augmented with the specific feedback provided by the evaluator, guiding the generator to produce a more suitable answer.\n",
    "-   **Seamless Integration into Gradio Chat Interface:** The entire multi-step workflow—initial generation, evaluation, and conditional re-run with feedback—is integrated into the `gradio` chat interface built previously. The core `chat` callback function is extended to orchestrate this complex interaction logic transparently to the end-user.\n",
    "-   **Live Demonstration of Self-Correction:** The lab includes a clever demonstration where an \"unprofessional\" response is deliberately forced (by instructing `gpt-4o-mini` to reply in Pig Latin for specific questions). This successfully triggers a negative evaluation from Gemini, followed by a corrected, professional response from `gpt-4o-mini` on the re-run, vividly illustrating the self-correction capability of the implemented workflow.\n",
    "-   **Detailed Prompt Engineering for Distinct Roles:** The session underscores the importance of crafting distinct and detailed system prompts for both the generator and evaluator LLMs. Each prompt is tailored to the specific role, context, and output requirements of the respective LLM.\n",
    "-   **Commercial Viability of Validation Loops:** The instructor emphasizes that incorporating such automated evaluation and feedback loops is a highly practical and commercially valuable technique for enhancing the reliability, quality, and safety of LLM-generated content in real-world business applications.\n",
    "-   **Conceptual Link Between Structured Outputs and Tool Use:** Students are encouraged to recognize the underlying similarity between structured outputs (where an LLM generates data conforming to a schema) and tool use (where an LLM generates a structured JSON request for a tool). Both involve the LLM producing machine-readable structured data that developer-written code can then act upon.\n",
    "\n",
    "---\n",
    "### Conceptual Understanding\n",
    "-   **Pydantic (`BaseModel` for Data Validation and Schemas)**\n",
    "    1.  **Why is this concept important?** Pydantic is a Python library that leverages Python type annotations for data validation and settings management. By creating a class that inherits from `pydantic.BaseModel`, developers can define a clear, explicit schema for their data structures, including field types, default values, and custom validation logic. Pydantic then automatically validates incoming data against this schema at runtime, parses it into well-typed objects, and can serialize these objects back into formats like JSON.\n",
    "    2.  **How does it connect to real-world tasks, problems, or applications?** Pydantic is extensively used in modern Python development for validating API request and response bodies (e.g., in FastAPI), managing application configurations, and, as demonstrated in this lab, defining the expected structure of data to be returned by LLMs when using \"structured output\" features. It enhances data integrity, reduces boilerplate validation code, and improves code readability and robustness.\n",
    "    3.  **Which related techniques or areas should be studied alongside this concept?** Python type hints, data serialization formats (JSON, YAML), data validation principles, API design, and other schema definition languages or tools (e.g., JSON Schema, Marshmallow).\n",
    "\n",
    "-   **Structured Outputs from LLMs**\n",
    "    1.  **Why is this concept important?** \"Structured outputs\" refers to the capability of some Large Language Model APIs to generate responses that are guaranteed to conform to a predefined data schema (such as a Pydantic model or a JSON Schema). This is a significant advancement over simply parsing free-form text, as it ensures that the LLM's output is reliably machine-readable and can be directly integrated into application logic without complex and error-prone parsing routines.\n",
    "    2.  **How does it connect to real-world tasks, problems, or applications?** This feature is crucial for any application that needs to reliably extract specific pieces of information from an LLM's response, populate data objects, trigger specific actions based on LLM decisions, or ensure interoperability with other systems that expect data in a particular structured format. In this lab, it is used to ensure the Gemini evaluator LLM returns a consistent `Evaluation` object.\n",
    "    3.  **Which related techniques or areas should be studied alongside this concept?** JSON Schema, Pydantic model definition, LLM function calling/tool use (which also heavily relies on the LLM generating structured JSON), reliable data extraction techniques from text, and API features of specific LLM providers that support structured outputs.\n",
    "\n",
    "-   **Evaluator-Optimizer Agentic Design Pattern**\n",
    "    1.  **Why is this concept important?** The Evaluator-Optimizer pattern is an agentic design where one AI agent (the \"Optimizer\" or generator) produces an initial output (e.g., text, code, a plan), and a second AI agent (the \"Evaluator\") critically assesses this output against a set of predefined criteria or goals. If the output is deemed insufficient or incorrect, the Evaluator provides specific feedback, which the Optimizer then uses to generate a revised and potentially improved output. This iterative loop mimics human review and refinement processes.\n",
    "    2.  **How does it connect to real-world tasks, problems, or applications?** This pattern is highly valuable for enhancing the quality, accuracy, and reliability of AI-generated content. It can be applied to tasks like improving AI-written essays or reports, refining generated software code, ensuring summaries are factual and comprehensive, enforcing specific stylistic constraints in creative writing, or making AI-generated plans more robust and feasible.\n",
    "    3.  **Which related techniques or areas should be studied alongside this concept?** Multi-agent systems, Reinforcement Learning from AI Feedback (RLAIF) which is a more formal machine learning approach building on similar ideas, quality assurance methodologies for AI systems, iterative design processes, and crafting effective feedback mechanisms for AI agents.\n",
    "\n",
    "---\n",
    "### Reflective Questions\n",
    "1.  **Application:** The lab's Evaluator-Optimizer pattern uses Gemini to check `gpt-4o-mini`'s response. In a scenario where an LLM is drafting legal contract clauses, how could an evaluator LLM be specifically prompted to ensure both legal accuracy (based on provided legal principles as a resource) and avoidance of ambiguous language?\n",
    "    * *Answer:* The evaluator LLM for legal clauses could be prompted with: \"Assess the provided contract clause for: 1. Strict adherence to the following legal principles [insert principles]. 2. Clarity and unambiguity, flagging any phrases open to multiple interpretations. Provide `is_acceptable: bool` and detailed `feedback` pinpointing specific issues and suggesting rephrasing for clarity if needed.\"\n",
    "2.  **Teaching:** How would you explain the practical difference and benefit of using an LLM with \"structured outputs\" (to populate a Pydantic model) versus an LLM that just generates a natural language evaluation like \"The response was good and professional,\" to a project manager overseeing an AI project?\n",
    "    * *Answer:* \"If the LLM just says 'The response was good,' our software has to guess what 'good' means and if any action is needed. With 'structured outputs,' the LLM fills out a precise form, like `is_acceptable: true`, `feedback: 'Directly answers question.'` This form is instantly understood by our software, allowing us to reliably automate next steps, like approving the response or triggering a re-do with specific reasons, making our system more robust and less prone to misinterpretation.\"\n",
    "3.  **Extension:** The current \"rerun\" mechanism feeds back the rejected answer and the reason. To prevent the generator LLM from getting stuck in a loop of making similar mistakes, what additional strategy or information could the *evaluator LLM* be tasked to provide in its `feedback` field that would more proactively guide the generator towards a successful revision?\n",
    "    * *Answer:* The evaluator LLM could be tasked to include a \"concrete suggestion for improvement\" or even a \"brief example of an acceptable phrasing\" within its `feedback` string. For instance, instead of just \"unprofessional due to Pig Latin,\" it might add, \"Suggestion: Rephrase directly in standard English, focusing on the patent details,\" which offers more actionable guidance to the generator LLM to break out of repetitive error patterns.\n",
    "\n",
    "# Day 4 - Building Agentic LLM Workflows: Resources, Tools & Structured Outputs\n",
    "\n",
    "### Summary\n",
    "This advanced lab session meticulously constructs a complete \"Evaluator-Optimizer\" agentic workflow by directly orchestrating Large Language Model (LLM) API calls, deliberately avoiding formal agentic frameworks to provide deeper insight into their mechanics. The system employs a primary LLM (`gpt-4o-mini`) to generate answers to user queries based on previously established \"resources\" (personal information). A second LLM (Google's Gemini Flash) then acts as an evaluator, leveraging \"structured outputs\" defined by Pydantic models to assess the primary LLM's response for acceptability and provide feedback. If a response is deemed unsatisfactory, the primary LLM is triggered to re-attempt the answer, this time incorporating the evaluator's specific feedback, with the entire interaction seamlessly managed within a Gradio-powered chat interface, thus demonstrating a practical, framework-less method for building self-correcting and higher-quality AI systems.\n",
    "\n",
    "---\n",
    "### Highlights\n",
    "-   **Framework-less Evaluator-Optimizer Workflow Implementation:** The core achievement of this lab is the successful construction of a sophisticated agentic pattern—where one LLM evaluates and provides feedback to another for iterative improvement—entirely through direct LLM API calls. This approach bypasses formal agentic frameworks, offering students a transparent understanding of the fundamental interactions involved.\n",
    "-   **Pydantic for Defining Data Schemas:** The `pydantic` library is introduced and utilized to create a well-defined data structure (an `Evaluation` class inheriting from `BaseModel`, with fields `is_acceptable: bool` and `feedback: str`). This schema dictates the format for the evaluator LLM's assessment, ensuring its output is consistent and programmatically usable.\n",
    "-   **Leveraging Structured Outputs with LLMs (Gemini Example):** A key technique showcased is \"structured outputs.\" The evaluator LLM (Gemini Flash) is specifically instructed to format its response according to the predefined `Evaluation` Pydantic model. The underlying LLM client library then automatically parses the LLM's native JSON output into a Python `Evaluation` object, greatly simplifying the process of extracting structured data from the LLM.\n",
    "-   **Dual LLM System Architecture (Generator & Evaluator):**\n",
    "    -   **Generator LLM (`gpt-4o-mini`):** This model is responsible for generating the initial user-facing responses, drawing upon the \"resources\" (user's LinkedIn profile and summary) established in the previous lab segment.\n",
    "    -   **Evaluator LLM (Gemini Flash):** This model's role is to critically assess the generator's output. It receives its own system prompt, which includes the same contextual resources as the generator, along with instructions to evaluate the professionalism and appropriateness of the response.\n",
    "-   **Conditional Re-run Mechanism with Feedback Loop:** If the evaluator LLM (Gemini) determines that the initial response from the generator LLM (`gpt-4o-mini`) is unacceptable (e.g., `evaluation.is_acceptable == False`), the system automatically triggers a second call to the generator. Crucially, the prompt for this re-run is augmented with the specific feedback provided by the evaluator, guiding the generator to produce a more suitable answer.\n",
    "-   **Seamless Integration into Gradio Chat Interface:** The entire multi-step workflow—initial generation, evaluation, and conditional re-run with feedback—is integrated into the `gradio` chat interface built previously. The core `chat` callback function is extended to orchestrate this complex interaction logic transparently to the end-user.\n",
    "-   **Live Demonstration of Self-Correction:** The lab includes a clever demonstration where an \"unprofessional\" response is deliberately forced (by instructing `gpt-4o-mini` to reply in Pig Latin for specific questions). This successfully triggers a negative evaluation from Gemini, followed by a corrected, professional response from `gpt-4o-mini` on the re-run, vividly illustrating the self-correction capability of the implemented workflow.\n",
    "-   **Detailed Prompt Engineering for Distinct Roles:** The session underscores the importance of crafting distinct and detailed system prompts for both the generator and evaluator LLMs. Each prompt is tailored to the specific role, context, and output requirements of the respective LLM.\n",
    "-   **Commercial Viability of Validation Loops:** The instructor emphasizes that incorporating such automated evaluation and feedback loops is a highly practical and commercially valuable technique for enhancing the reliability, quality, and safety of LLM-generated content in real-world business applications.\n",
    "-   **Conceptual Link Between Structured Outputs and Tool Use:** Students are encouraged to recognize the underlying similarity between structured outputs (where an LLM generates data conforming to a schema) and tool use (where an LLM generates a structured JSON request for a tool). Both involve the LLM producing machine-readable structured data that developer-written code can then act upon.\n",
    "\n",
    "---\n",
    "### Conceptual Understanding\n",
    "-   **Pydantic (`BaseModel` for Data Validation and Schemas)**\n",
    "    1.  **Why is this concept important?** Pydantic is a Python library that leverages Python type annotations for data validation and settings management. By creating a class that inherits from `pydantic.BaseModel`, developers can define a clear, explicit schema for their data structures, including field types, default values, and custom validation logic. Pydantic then automatically validates incoming data against this schema at runtime, parses it into well-typed objects, and can serialize these objects back into formats like JSON.\n",
    "    2.  **How does it connect to real-world tasks, problems, or applications?** Pydantic is extensively used in modern Python development for validating API request and response bodies (e.g., in FastAPI), managing application configurations, and, as demonstrated in this lab, defining the expected structure of data to be returned by LLMs when using \"structured output\" features. It enhances data integrity, reduces boilerplate validation code, and improves code readability and robustness.\n",
    "    3.  **Which related techniques or areas should be studied alongside this concept?** Python type hints, data serialization formats (JSON, YAML), data validation principles, API design, and other schema definition languages or tools (e.g., JSON Schema, Marshmallow).\n",
    "\n",
    "-   **Structured Outputs from LLMs**\n",
    "    1.  **Why is this concept important?** \"Structured outputs\" refers to the capability of some Large Language Model APIs to generate responses that are guaranteed to conform to a predefined data schema (such as a Pydantic model or a JSON Schema). This is a significant advancement over simply parsing free-form text, as it ensures that the LLM's output is reliably machine-readable and can be directly integrated into application logic without complex and error-prone parsing routines.\n",
    "    2.  **How does it connect to real-world tasks, problems, or applications?** This feature is crucial for any application that needs to reliably extract specific pieces of information from an LLM's response, populate data objects, trigger specific actions based on LLM decisions, or ensure interoperability with other systems that expect data in a particular structured format. In this lab, it is used to ensure the Gemini evaluator LLM returns a consistent `Evaluation` object.\n",
    "    3.  **Which related techniques or areas should be studied alongside this concept?** JSON Schema, Pydantic model definition, LLM function calling/tool use (which also heavily relies on the LLM generating structured JSON), reliable data extraction techniques from text, and API features of specific LLM providers that support structured outputs.\n",
    "\n",
    "-   **Evaluator-Optimizer Agentic Design Pattern**\n",
    "    1.  **Why is this concept important?** The Evaluator-Optimizer pattern is an agentic design where one AI agent (the \"Optimizer\" or generator) produces an initial output (e.g., text, code, a plan), and a second AI agent (the \"Evaluator\") critically assesses this output against a set of predefined criteria or goals. If the output is deemed insufficient or incorrect, the Evaluator provides specific feedback, which the Optimizer then uses to generate a revised and potentially improved output. This iterative loop mimics human review and refinement processes.\n",
    "    2.  **How does it connect to real-world tasks, problems, or applications?** This pattern is highly valuable for enhancing the quality, accuracy, and reliability of AI-generated content. It can be applied to tasks like improving AI-written essays or reports, refining generated software code, ensuring summaries are factual and comprehensive, enforcing specific stylistic constraints in creative writing, or making AI-generated plans more robust and feasible.\n",
    "    3.  **Which related techniques or areas should be studied alongside this concept?** Multi-agent systems, Reinforcement Learning from AI Feedback (RLAIF) which is a more formal machine learning approach building on similar ideas, quality assurance methodologies for AI systems, iterative design processes, and crafting effective feedback mechanisms for AI agents.\n",
    "\n",
    "---\n",
    "### Reflective Questions\n",
    "1.  **Application:** The lab's Evaluator-Optimizer pattern uses Gemini to check `gpt-4o-mini`'s response. In a scenario where an LLM is drafting legal contract clauses, how could an evaluator LLM be specifically prompted to ensure both legal accuracy (based on provided legal principles as a resource) and avoidance of ambiguous language?\n",
    "    * *Answer:* The evaluator LLM for legal clauses could be prompted with: \"Assess the provided contract clause for: 1. Strict adherence to the following legal principles [insert principles]. 2. Clarity and unambiguity, flagging any phrases open to multiple interpretations. Provide `is_acceptable: bool` and detailed `feedback` pinpointing specific issues and suggesting rephrasing for clarity if needed.\"\n",
    "2.  **Teaching:** How would you explain the practical difference and benefit of using an LLM with \"structured outputs\" (to populate a Pydantic model) versus an LLM that just generates a natural language evaluation like \"The response was good and professional,\" to a project manager overseeing an AI project?\n",
    "    * *Answer:* \"If the LLM just says 'The response was good,' our software has to guess what 'good' means and if any action is needed. With 'structured outputs,' the LLM fills out a precise form, like `is_acceptable: true`, `feedback: 'Directly answers question.'` This form is instantly understood by our software, allowing us to reliably automate next steps, like approving the response or triggering a re-do with specific reasons, making our system more robust and less prone to misinterpretation.\"\n",
    "3.  **Extension:** The current \"rerun\" mechanism feeds back the rejected answer and the reason. To prevent the generator LLM from getting stuck in a loop of making similar mistakes, what additional strategy or information could the *evaluator LLM* be tasked to provide in its `feedback` field that would more proactively guide the generator towards a successful revision?\n",
    "    * *Answer:* The evaluator LLM could be tasked to include a \"concrete suggestion for improvement\" or even a \"brief example of an acceptable phrasing\" within its `feedback` string. For instance, instead of just \"unprofessional due to Pig Latin,\" it might add, \"Suggestion: Rephrase directly in standard English, focusing on the patent details,\" which offers more actionable guidance to the generator LLM to break out of repetitive error patterns.\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
