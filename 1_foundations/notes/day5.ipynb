{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "491b48b9",
   "metadata": {},
   "source": [
    "# Day 5 - Building Your Career Alter Ego: LLM Function Calling with Push Alerts\n",
    "\n",
    "### Summary\n",
    "This transcript introduces the foundational concept of enabling Large Language Models (LLMs) to use custom tools by directly interacting with the model's API, without relying on higher-level frameworks. The purpose is to build a \"personal career alter ego\" chatbot capable of performing actions like recording user details or unknown questions via push notifications, emphasizing the importance of understanding the underlying JSON-based communication for tool use. This knowledge is crucial for data scientists to develop more interactive and capable AI applications by extending LLM functionalities to real-world tasks.\n",
    "\n",
    "### Highlights\n",
    "* **Direct LLM Interaction for Foundational Knowledge**: The tutorial stresses the importance of working directly with LLMs (e.g., through OpenAI's API) before using agentic frameworks. This approach provides a deep understanding of the core mechanisms, which is invaluable when debugging or customizing complex systems.\n",
    "* **Pushover for Simple Push Notifications**: Pushover is introduced as a straightforward and cost-effective tool for sending push notifications to a phone. This is presented as an alternative to more complex services like Twilio, especially for personal projects or quick notifications, facilitating real-time alerts from applications.\n",
    "* **Defining Custom Functions as Tools**: Python functions (`record_user_details`, `record_unknown_question`) are created to perform specific actions. These functions serve as \"tools\" that the LLM can decide to use, enabling the AI to interact with external systems or log information dynamically.\n",
    "* **JSON for Tool Specification**: The critical aspect of tool use is describing these Python functions to the LLM using a detailed JSON structure. This JSON object specifies the tool's name, description, parameters (name, type, description, required), which the LLM uses to understand its capabilities and when to invoke it.\n",
    "* **Mechanism of Tool Invocation**: The LLM doesn't directly execute the Python code. Instead, based on the user's query and the JSON tool descriptions provided, the LLM's response will indicate *which* tool it wants to use and with *what arguments* (also in JSON format). The developer's code then parses this and executes the corresponding Python function.\n",
    "* **Boilerplate Nature of Tool Definitions**: The transcript acknowledges that the JSON definitions for tools can be verbose and contain repetitive boilerplate. This highlights why agentic frameworks, which automate this definition process, are popular for more complex applications.\n",
    "* **Practical Tool Examples**:\n",
    "    * `record_user_details`: A tool to capture a user's name, email, and notes, sending a push notification to the developer. Useful for lead generation or follow-ups in a career chatbot.\n",
    "    * `record_unknown_question`: A tool to log questions the LLM cannot answer, again via a push notification. This is valuable for identifying knowledge gaps and improving the LLM's information base or conversational abilities.\n",
    "* **List of Tools**: Multiple tool JSON definitions are grouped into a list, which is then passed to the LLM during an API call. This allows the LLM to choose from a suite of available tools.\n",
    "\n",
    "### Conceptual Understanding\n",
    "-   **LLM Tool Use: JSON Descriptions and Conditional Execution**\n",
    "    1.  **Why is this concept important?** Understanding that LLM tool use fundamentally relies on structured JSON descriptions demystifies how an LLM can \"decide\" to perform actions. The LLM isn't executing code; it's pattern-matching the user's intent against the tool descriptions you provide and then outputting a structured request (often JSON) for your code to execute the tool. The \"if statements\" refer to the developer's backend logic that checks if the LLM requested a tool and then calls the appropriate function.\n",
    "    2.  **How does it connect to real-world tasks, problems, or applications?** This is the basis for enabling LLMs to interact with any API or external system. For example, a travel assistant LLM could use tools to check flight availability (calling a flight API), a data analysis LLM could use a tool to execute a SQL query (interacting with a database), or a smart home LLM could control lights (calling a smart home API). The JSON provides a universal language for these interactions.\n",
    "    3.  **Which related techniques or areas should be studied alongside this concept?**\n",
    "        * **Function Calling**: Specifically how APIs like OpenAI's implement this, including the format of the LLM's request to call a function and the expected format of the response back to the LLM.\n",
    "        * **Agentic Frameworks (e.g., LangChain, LlamaIndex)**: Once the basics are understood, these frameworks can abstract away much of the boilerplate JSON creation and execution logic, allowing for faster development of complex multi-tool agents.\n",
    "        * **API Design**: Understanding how to design and interact with RESTful APIs is crucial, as many tools will wrap calls to such APIs.\n",
    "        * **Prompt Engineering**: Crafting effective prompts and tool descriptions is key to ensuring the LLM uses the tools correctly and appropriately.\n",
    "\n",
    "### Code Examples\n",
    "-   **Pushover Notification Function (`push`)**:\n",
    "    ```python\n",
    "    import requests\n",
    "    import os\n",
    "    # Assuming PUSHOVER_USER, PUSHOVER_TOKEN are in .env file and loaded\n",
    "    # from dotenv import load_dotenv\n",
    "    # load_dotenv()\n",
    "\n",
    "    pushover_user = os.getenv(\"PUSHOVER_USER\")\n",
    "    pushover_token = os.getenv(\"PUSHOVER_TOKEN\")\n",
    "    pushover_url = \"https://api.pushover.net/1/messages.json\"\n",
    "\n",
    "    def push(message):\n",
    "        data = {\n",
    "            \"user\": pushover_user,\n",
    "            \"token\": pushover_token,\n",
    "            \"message\": message\n",
    "        }\n",
    "        requests.post(pushover_url, data=data)\n",
    "\n",
    "    # Example usage:\n",
    "    # push(\"Hey\")\n",
    "    ```\n",
    "\n",
    "-   **Tool Function: `record_user_details`**:\n",
    "    ```python\n",
    "    def record_user_details(email, name=None, notes=None):\n",
    "        message = f\"Recording interest from: Email: {email}\"\n",
    "        if name:\n",
    "            message += f\", Name: {name}\"\n",
    "        if notes:\n",
    "            message += f\", Notes: {notes}\"\n",
    "        push(message) # Uses the push notification function\n",
    "        return f\"Successfully recorded interest for {email}.\"\n",
    "    ```\n",
    "\n",
    "-   **Tool Function: `record_unknown_question`**:\n",
    "    ```python\n",
    "    def record_unknown_question(question):\n",
    "        message = f\"Recording a question I couldn't answer: {question}\"\n",
    "        push(message)\n",
    "        return \"Successfully recorded the unknown question.\"\n",
    "    ```\n",
    "\n",
    "-   **JSON Definition for `record_user_details` Tool**:\n",
    "    ```json\n",
    "    record_user_details_json = {\n",
    "        \"name\": \"record_user_details\",\n",
    "        \"description\": \"Use this tool to record that a user is interested in being in touch and provided an email address.\",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"email\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"The email address provided by the user.\"\n",
    "                },\n",
    "                \"name\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"The name of the user, if provided.\"\n",
    "                },\n",
    "                \"notes\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"Any additional notes or context provided by the user.\"\n",
    "                }\n",
    "            },\n",
    "            \"required\": [\"email\"],\n",
    "            \"additionalProperties\": False\n",
    "        }\n",
    "    }\n",
    "    ```\n",
    "\n",
    "-   **JSON Definition for `record_unknown_question` Tool**:\n",
    "    ```json\n",
    "    record_unknown_question_json = {\n",
    "        \"name\": \"record_unknown_question\",\n",
    "        \"description\": \"Use this tool if the user asks a question that you don't know how to answer.\",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"question\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"The specific question that couldn't be answered.\"\n",
    "                }\n",
    "            },\n",
    "            \"required\": [\"question\"],\n",
    "            \"additionalProperties\": False\n",
    "        }\n",
    "    }\n",
    "    ```\n",
    "\n",
    "-   **List of Tools for the LLM**:\n",
    "    ```python\n",
    "    tools = [\n",
    "        {\n",
    "            \"type\": \"function\",\n",
    "            \"function\": record_user_details_json\n",
    "        },\n",
    "        {\n",
    "            \"type\": \"function\",\n",
    "            \"function\": record_unknown_question_json\n",
    "        }\n",
    "    ]\n",
    "    # This 'tools' list would be passed to the OpenAI API client\n",
    "    ```\n",
    "\n",
    "### Reflective Questions\n",
    "1.  **Application:** Which specific dataset or project could benefit from custom LLM tools like `record_user_details` and `record_unknown_question`?\n",
    "    * *Answer:* A customer support chatbot for a SaaS product could use `record_user_details` to capture leads for complex issues requiring human follow-up and `record_unknown_question` to flag queries about unreleased features or gaps in its knowledge base, thereby directly informing product development and documentation updates.\n",
    "\n",
    "2.  **Teaching:** How would you explain the purpose of the JSON tool description to a junior colleague, using one concrete example?\n",
    "    * *Answer:* \"Imagine the LLM is a manager who can't do tasks themselves but can delegate. The JSON tool description is like a detailed job card for a task, e.g., 'Order Pizza.' It specifies the task name ('order_pizza'), what it does ('orders a pizza'), and what info it needs ('crust_type', 'toppings'), so the manager knows when and how to ask someone (our code) to do it.\"\n",
    "\n",
    "3.  **Extension:** What related technique or area, beyond basic tool use, should you explore next to build more sophisticated LLM applications, and why?\n",
    "    * *Answer:* Explore **agentic systems and planning capabilities** (e.g., ReAct - Reason+Act prompting or frameworks like LangChain Agents). This allows the LLM to not just use a single tool, but to chain multiple tool uses and observations together to achieve more complex, multi-step goals, which is essential for building truly intelligent and autonomous applications.\n",
    "\n",
    "# Day 5 - LLM Tool Calls Demystified: How to Process and Execute Function Requests\n",
    "\n",
    "### Summary\n",
    "This technical guide details the fundamental process of enabling Large Language Models (LLMs) to use custom tools by directly interacting with their API, moving from defining tools as JSON to actively handling the LLM's requests to use them. It explains how to write Python functions that parse the LLM's tool-use intentions (which are returned as structured JSON), execute the corresponding Python code, and then format the results to potentially send back to the LLM. This foundational understanding of direct model interaction and tool execution logic (using both explicit if-statements and dynamic function calling) is vital for data scientists before they leverage abstraction frameworks, empowering them to build robust and debuggable AI applications that can perform real-world actions.\n",
    "\n",
    "### Highlights\n",
    "* **Direct LLM Interaction for Foundational Knowledge**: The tutorial stresses the importance of working directly with LLMs (e.g., through OpenAI's API) before using agentic frameworks. This approach provides a deep understanding of the core mechanisms, invaluable for debugging or customizing.\n",
    "* **Pushover for Simple Push Notifications**: Pushover is used as a straightforward tool for sending push notifications, demonstrating how tools can interact with external services.\n",
    "* **Defining Custom Functions as Tools & JSON Specification**: Python functions (e.g., `record_user_details`) are defined as tools, and their capabilities are described to the LLM using a specific JSON schema (name, description, parameters). This structured format is how the LLM understands and chooses tools.\n",
    "* **`handle_tool_calls` Function for Execution**: A key function, `handle_tool_calls`, is introduced to process the LLM's response when it decides to use a tool. It iterates through the `tool_calls` list provided by the LLM.\n",
    "* **Parsing LLM's Tool Request**: The LLM's response contains structured JSON (converted to an object) indicating the `function.name` it wants to call and the `function.arguments` it wants to pass. This data must be parsed by the developer's code.\n",
    "* **Conditional Execution via If-Statements**: The initial, straightforward method for dispatching tool calls involves using `if-elif-else` statements to check the `tool_name` (function name from the LLM) and then call the appropriate local Python function with the parsed arguments.\n",
    "* **Dynamic Function Calling using `globals()`**: A more \"Pythonic\" and concise alternative to lengthy if-statements is demonstrated using `globals()['function_name'](**arguments)` to dynamically look up and call the Python function based on the string name provided by the LLM.\n",
    "* **Conceptual Equivalence (\"Glorified If-Statement\")**: Despite the elegance of dynamic dispatch, the underlying logic is still a mapping from a requested tool name to a concrete function call, conceptually similar to an if-statement.\n",
    "* **Appending Tool Results to Message History**: The output from the executed tool function is captured and should be appended to the conversation history (typically as a message with `role=\"tool\"`, including `tool_call_id` and `content` which is the tool's output). This result is then sent back to the LLM in the next API call so it can use this information to form its subsequent response.\n",
    "* **Abstraction by Frameworks**: The process of defining tools, parsing requests, dispatching calls, and handling results is complex. The tutorial notes that agentic frameworks (e.g., LangChain) automate these steps, but understanding this manual process is crucial for grasping what those frameworks do \"under the hood.\"\n",
    "\n",
    "### Conceptual Understanding\n",
    "-   **LLM Tool Use: From JSON Intention to Python Execution**\n",
    "    1.  **Why is this concept important?** It bridges the gap between an LLM's text-based reasoning and performing concrete actions in a software environment. The LLM signals *intent* to use a tool with specific parameters (via JSON in its response). The developer's code then acts as the *execution engine*, translating that intent into actual function calls. This separation is key for security and control.\n",
    "    2.  **How does it connect to real-world tasks, problems, or applications?** This entire workflow (defining tools, LLM signals intent, code executes tool, result fed back to LLM) is the backbone of most interactive AI assistants or agents. For example:\n",
    "        * A data science assistant might have a tool to execute Python code for plotting. The LLM asks to use the \"plot_data\" tool with column names; your `handle_tool_calls` function runs the plotting library and returns the image path or status.\n",
    "        * An e-commerce bot uses a tool to check inventory. The LLM requests to use \"check_stock\" for \"product_id_123\"; your code queries the database and returns the stock count.\n",
    "    3.  **Which related techniques or areas should be studied alongside this concept?**\n",
    "        * **OpenAI Function Calling/Tool Calling API Details**: The specific request and response formats for `tool_calls` and how to structure `messages` with `role: tool`.\n",
    "        * **Error Handling in Tool Execution**: Robustly handling cases where a tool fails, parameters are invalid, or the LLM hallucinates tool names/arguments.\n",
    "        * **Sequential Tool Use and Planning**: How an LLM can make multiple tool calls in sequence, or how to build systems where the LLM plans a series of tool uses to achieve a complex goal (often managed by agentic frameworks).\n",
    "        * **Security Implications**: Understanding the risks of allowing an LLM to trigger arbitrary code execution, especially with dynamic methods like `globals()`, and implementing safeguards.\n",
    "\n",
    "### Code Examples\n",
    "-   **Pushover Notification Function (`push`)**:\n",
    "    ```python\n",
    "    import requests\n",
    "    import os\n",
    "    # Assuming PUSHOVER_USER, PUSHOVER_TOKEN are in .env file and loaded\n",
    "    # from dotenv import load_dotenv\n",
    "    # load_dotenv()\n",
    "\n",
    "    pushover_user = os.getenv(\"PUSHOVER_USER\")\n",
    "    pushover_token = os.getenv(\"PUSHOVER_TOKEN\")\n",
    "    pushover_url = \"https://api.pushover.net/1/messages.json\"\n",
    "\n",
    "    def push(message):\n",
    "        data = {\n",
    "            \"user\": pushover_user,\n",
    "            \"token\": pushover_token,\n",
    "            \"message\": message\n",
    "        }\n",
    "        # In a real scenario, add error handling for the request\n",
    "        requests.post(pushover_url, data=data)\n",
    "    ```\n",
    "\n",
    "-   **Example Tool Functions**:\n",
    "    ```python\n",
    "    def record_user_details(email, name=None, notes=None):\n",
    "        message = f\"Recording interest from: Email: {email}\"\n",
    "        if name:\n",
    "            message += f\", Name: {name}\"\n",
    "        if notes:\n",
    "            message += f\", Notes: {notes}\"\n",
    "        push(message)\n",
    "        return f\"Successfully recorded interest for {email}.\"\n",
    "\n",
    "    def record_unknown_question(question):\n",
    "        message = f\"Recording a question I couldn't answer: {question}\"\n",
    "        push(message)\n",
    "        return \"Successfully recorded the unknown question.\"\n",
    "    ```\n",
    "\n",
    "-   **`handle_tool_calls` (If-Statement Version)**:\n",
    "    ```python\n",
    "    import json\n",
    "\n",
    "    # available_tools would map tool names to functions if not using globals() explicitly\n",
    "    # For this example, functions are directly called.\n",
    "\n",
    "    def handle_tool_calls_if_statements(tool_calls):\n",
    "        tool_outputs = []\n",
    "        for tool_call in tool_calls:\n",
    "            tool_name = tool_call.function.name\n",
    "            tool_args_str = tool_call.function.arguments\n",
    "            tool_args = json.loads(tool_args_str) # Arguments come as a JSON string\n",
    "\n",
    "            print(f\"Calling tool: {tool_name} with args: {tool_args}\")\n",
    "\n",
    "            if tool_name == \"record_user_details\":\n",
    "                result = record_user_details(**tool_args)\n",
    "            elif tool_name == \"record_unknown_question\":\n",
    "                result = record_unknown_question(**tool_args)\n",
    "            else:\n",
    "                result = f\"Unknown tool: {tool_name}\"\n",
    "\n",
    "            tool_outputs.append({\n",
    "                \"tool_call_id\": tool_call.id, # ID of the specific tool call from LLM response\n",
    "                \"role\": \"tool\",\n",
    "                \"name\": tool_name,\n",
    "                \"content\": result  # Content is the string result from the tool\n",
    "            })\n",
    "        return tool_outputs\n",
    "    ```\n",
    "\n",
    "-   **Dynamic Function Call using `globals()` (Illustrative Snippet)**:\n",
    "    ```python\n",
    "    # Illustrative example of calling a function dynamically\n",
    "    # question_to_record = {\"question\": \"This is a really hard question.\"}\n",
    "    # function_name_from_llm = \"record_unknown_question\"\n",
    "    #\n",
    "    # if function_name_from_llm in globals() and callable(globals()[function_name_from_llm]):\n",
    "    #     target_function = globals()[function_name_from_llm]\n",
    "    #     # Assuming arguments are already parsed into a dictionary (e.g., question_to_record)\n",
    "    #     # For OpenAI, arguments are a JSON string, so json.loads() is needed first.\n",
    "    #     # result = target_function(**json.loads(llm_provided_args_string))\n",
    "    #     result = target_function(**question_to_record)\n",
    "    #     print(f\"Dynamic call result: {result}\")\n",
    "    # else:\n",
    "    #     print(f\"Function {function_name_from_llm} not found or not callable.\")\n",
    "    ```\n",
    "\n",
    "-   **`handle_tool_calls` (Dynamic `globals()` Version)**:\n",
    "    ```python\n",
    "    import json\n",
    "\n",
    "    def handle_tool_calls_dynamic(tool_calls):\n",
    "        tool_outputs = []\n",
    "        for tool_call in tool_calls:\n",
    "            tool_name = tool_call.function.name\n",
    "            tool_args_str = tool_call.function.arguments\n",
    "            tool_args = json.loads(tool_args_str)\n",
    "\n",
    "            print(f\"Dynamically calling tool: {tool_name} with args: {tool_args}\")\n",
    "\n",
    "            if tool_name in globals() and callable(globals()[tool_name]):\n",
    "                function_to_call = globals()[tool_name]\n",
    "                try:\n",
    "                    result = function_to_call(**tool_args)\n",
    "                except Exception as e:\n",
    "                    result = f\"Error calling tool {tool_name}: {str(e)}\"\n",
    "            else:\n",
    "                result = f\"Unknown or non-callable tool: {tool_name}\"\n",
    "\n",
    "            tool_outputs.append({\n",
    "                \"tool_call_id\": tool_call.id,\n",
    "                \"role\": \"tool\",\n",
    "                \"name\": tool_name,\n",
    "                \"content\": result\n",
    "            })\n",
    "        return tool_outputs\n",
    "    ```\n",
    "\n",
    "### Reflective Questions\n",
    "1.  **Application:** Consider a data visualization project. How could the `handle_tool_calls` logic enable an LLM to generate visualizations based on user requests (e.g., \"Plot sales over time for product X\")?\n",
    "    * *Answer:* The `handle_tool_calls` function could dispatch to a `generate_plot` tool. The LLM would provide arguments like plot type (line, bar), data columns ('sales', 'time'), and filters ('product X'). The Python `generate_plot` function would then use Matplotlib or Seaborn to create the image and return its path or a status, which `handle_tool_calls` formats for the LLM.\n",
    "\n",
    "2.  **Teaching:** How would you explain the role and importance of the `tool_outputs` (containing `tool_call_id`, `role: tool`, `name`, and `content`) that are returned by `handle_tool_calls` to a junior developer?\n",
    "    * *Answer:* \"After our code runs a tool the LLM asked for, `tool_outputs` is the crucial feedback loop. It tells the LLM, 'For that specific request you made (the `tool_call_id`), here's the tool's name, and this is the actual result (`content`).' Without this, the LLM wouldn't know what happened and couldn't use that information in its next thought or response.\"\n",
    "\n",
    "3.  **Extension (Security):** What are the potential security risks of using the `globals()` method for dynamic function dispatch in `handle_tool_calls`, and how could these be mitigated?\n",
    "    * *Answer:* Using `globals()` can be risky if the `tool_name` string (coming from the LLM) is not strictly controlled, as it could potentially call any global function, including unintended or unsafe ones. Mitigation includes maintaining an explicit allow-list of callable tool names and validating `tool_name` against this list before attempting a `globals()` lookup, effectively combining the safety of if-statements with the conciseness of dynamic dispatch for approved tools.\n",
    "\n",
    "# Day 5- Building AI Assistants: Implementing Tools for Handling Unknown Questions\n",
    "\n",
    "### Summary\n",
    "This text explains the process of refining a system prompt for a Large Language Model (LLM) designed to answer questions based on a user's LinkedIn profile. Key modifications include instructing the LLM to use tools for recording unanswerable questions and for steering engaging users towards email, emphasizing that this detailed prompting, even if redundant with tool descriptions, improves reliability. The core insight for data science professionals is that LLMs, even when seemingly \"calling tools,\" are fundamentally next-token predictors, and their advanced behaviors emerge from this statistical process rather than true autonomy.\n",
    "\n",
    "### Highlights\n",
    "-   **Enhanced LLM Tool Usage**: The system prompt is updated to explicitly guide the LLM on when and how to use external tools, such as logging unanswered queries or suggesting email for extended discussions. This is crucial for developing interactive AI agents that can gracefully handle knowledge gaps and manage user engagement in data science applications like personalized assistants or sophisticated Q&A systems.\n",
    "-   **Prompt Redundancy for Reliability**: The speaker advocates for repeating critical instructions (like tool usage guidelines) in both the system prompt and the tool's descriptive JSON. This practice is a valuable takeaway for data scientists, as it increases the probability of the LLM behaving as intended, leading to more predictable and robust AI applications.\n",
    "-   **LLMs as Advanced Next-Token Predictors**: A fundamental clarification is provided: LLMs operate by predicting the most statistically likely sequence of tokens based on the input, including prompts and tool specifications. For data scientists, understanding this mechanism is vital for effective prompt engineering and demystifying complex LLM behaviors like \"tool calling,\" which are sophisticated pattern-matching outcomes, not acts of autonomous decision-making.\n",
    "-   **Biasing LLM Outputs Through Prompts**: The text underscores that detailed prompts, including context and explicit instructions, effectively bias the LLM towards generating tokens consistent with the desired objectives. This is a core principle in prompt engineering, enabling data scientists to steer LLM outputs for tasks ranging from information extraction to controlled dialogue management.\n",
    "-   **Avoiding Anthropomorphism of LLMs**: It's emphasized that while LLMs can perform complex tasks, they don't possess \"true autonomy\"; their capabilities are an emergent property of next-token prediction. This realistic perspective helps data scientists in setting appropriate expectations and designing more effective human-AI interaction systems, particularly in areas like automated decision support or research assistants.\n",
    "\n",
    "### Conceptual Understanding\n",
    "-   **LLMs as Next-Token Predictors and Tool Usage**\n",
    "    1.  **Why is this concept important?** Understanding that LLMs are fundamentally next-token predictors, even when \"using tools,\" is crucial because it demystifies their capabilities and aids in troubleshooting. It clarifies that the LLM isn't \"deciding\" to use a tool in a human sense but generating a token sequence (e.g., a JSON formatted function call) that has been made statistically probable by the prompt engineering and its training data.\n",
    "    2.  **How does it connect to real‑world tasks, problems, or applications?** In real-world data science applications, such as building AI agents that integrate with external APIs (e.g., for fetching live data, executing code, or interacting with databases), this understanding allows developers to design prompts and tool descriptions more effectively. If a tool isn't being invoked as expected, the root cause is likely that the prompt has not made the specific \"tool call\" token sequence sufficiently probable compared to alternative continuations, rather than the LLM \"refusing\" to cooperate.\n",
    "    3.  **Which related techniques or areas should be studied alongside this concept?** Key areas to study alongside this include advanced prompt engineering techniques (e.g., few-shot prompting, chain-of-thought), fine-tuning LLMs on specific tasks or datasets, understanding transformer architectures (especially attention mechanisms), and exploring how Reinforcement Learning from Human Feedback (RLHF) is used to better align LLMs with human instructions and desired behaviors, including reliable tool usage.\n",
    "\n",
    "### Reflective Questions\n",
    "1.  **Application:** Which specific dataset or project could benefit from an LLM that uses tools to record unanswerable questions as described? Provide a one‑sentence explanation.\n",
    "    -   *Answer:* An internal knowledge base chatbot for a large enterprise could significantly benefit, as recording unanswerable questions would help identify gaps in documentation or frequently misunderstood topics, directly feeding into content improvement cycles.\n",
    "2.  **Teaching:** How would you explain the concept that an LLM \"calling a tool\" is just next-token prediction to a junior colleague, using one concrete example? Keep it under two sentences.\n",
    "    -   *Answer:* Think of it like a super-advanced autocomplete: if the prompt and context strongly suggest an action, like \"What's the weather in Paris?\", the LLM predicts the most likely next 'words' are a special command like `CALL_WEATHER_API(\"Paris\")` because it has learned this pattern leads to useful answers. It's not deciding, just outputting the statistically most probable sequence.\n",
    "\n",
    "# Day 5 - Creating & Deploying an AI Agent: From Chat Loop to HuggingFace Spaces\n",
    "\n",
    "### Summary\n",
    "This transcript meticulously explains the architecture and deployment of an advanced chat function where a Large Language Model (LLM) can utilize external tools. It details the iterative process: the LLM signals its intent to use a tool, the system executes the tool, feeds the result back to the LLM, and repeats until a final user-facing response is generated. The text then provides a comprehensive guide on structuring this application into a Python module (`App.py`) using Gradio for the interface, and deploying it to production via Hugging Face Spaces, enabling data scientists to create and share interactive AI agents, such as a \"virtual resume.\"\n",
    "\n",
    "### Highlights\n",
    "-   **Iterative Tool Calling Mechanism**: The chat function employs a crucial `while` loop. It calls the OpenAI API, and if the LLM's `finish_reason` is `tool_calls`, the system executes the specified tool(s), appends the results to the message history, and re-queries the LLM. This iterative cycle is fundamental for enabling LLMs to interact with external systems and is a cornerstone of agentic AI design.\n",
    "-   **Explicit Tool Declaration to LLM**: During the API call (`OpenAI.ChatCompletion.create`), a `tools` parameter containing a JSON description of available functions, their purpose, and schemas is passed. This allows the LLM to understand its capabilities and correctly format requests for tool execution, which is vital for data scientists integrating custom functionalities.\n",
    "-   **`handle_tool_calls` for Modular Tool Execution**: A distinct `handle_tool_calls` function is used to interpret the LLM's request and dispatch it to the correct Python function that implements the tool. This separation of concerns is a good software engineering practice, allowing data scientists to easily add or modify tools without altering the core chat logic.\n",
    "-   **Demonstrated Practical Tool Integration**: The system is shown to work with examples like responding to \"Who is your favorite musician?\" by triggering a tool (simulated by a phone notification for an unanswerable question) and handling \"I'd like to get in touch\" by using a tool to capture email information. These examples showcase real-world utility in data science applications needing external interactions or data logging.\n",
    "-   **Application Structuring in `App.py`**: The entire application, including tool definitions, the core chat logic within a class, and the Gradio user interface, is encapsulated in `App.py`. This modularization is a key step for preparing data science projects for deployment and maintainability.\n",
    "-   **Local Development with Gradio**: The use of Gradio for creating a local web interface allows for rapid testing and debugging of the chat application before deployment. This is a practical step for data scientists to ensure functionality in a controlled environment.\n",
    "-   **Simplified Deployment with Hugging Face Spaces**: Hugging Face Spaces, coupled with the `gradio deploy` command, offers a streamlined path to deploy Gradio applications. This makes complex AI applications more accessible for data scientists to share and showcase their work publicly or privately.\n",
    "-   **Secure Secret Management**: The deployment process emphasizes the importance of providing API keys (e.g., OpenAI, Pushover) as secrets within the Hugging Face Spaces environment, rather than hardcoding them. This is a critical security measure for any deployed application.\n",
    "-   **Vision of Agentic AI for Professional Use**: The transcript promotes the idea of such interactive chatbots serving as \"virtual resumes\" or personal AI avatars. This positions agentic AI as a novel way for data science professionals to demonstrate their capabilities directly.\n",
    "-   **Criticality of the Chat Loop Logic**: The speaker underscores the importance of understanding the detailed mechanics of the chat loop—API call, checking `finish_reason`, handling tool calls, and iterating. This understanding is essential for anyone building or troubleshooting LLM-based agents.\n",
    "\n",
    "### Conceptual Understanding\n",
    "-   **Iterative LLM Calls for Tool Execution**\n",
    "    1.  **Why is this concept important?** Standard LLM interactions often involve a single prompt and a single response. However, for an LLM to use tools (like searching a database, running code, or calling an external API), a multi-step, iterative process is usually required. The LLM first indicates its *intention* to use a specific tool with certain parameters. The external code then executes this tool, obtains a result, and this result is then fed back to the LLM in a *new* prompt. The LLM can then use this information to generate a final response or decide to call another tool. This iterative approach is what gives LLMs the appearance of \"acting\" or \"reasoning\" about external data.\n",
    "    2.  **How does it connect to real‑world tasks, problems, or applications?** This iterative tool-use pattern is fundamental to many advanced LLM applications:\n",
    "        * **Retrieval Augmented Generation (RAG):** An LLM decides to call a \"retrieval tool\" to search a knowledge base for relevant documents. The retrieved text is then passed back to the LLM, which uses it to formulate a comprehensive answer.\n",
    "        * **AI Agents for Task Automation:** An agent might plan a task (e.g., booking a flight), then make a series of tool calls (check availability, confirm price, make booking), with each step's result informing the next.\n",
    "        * **Data Analysis & Visualization:** A user might ask an LLM to \"plot sales data for Q3.\" The LLM would request a tool call to a code interpreter, passing Python code to generate the plot. The image or a status message is then returned to the LLM to present to the user.\n",
    "    3.  **Which related techniques or areas should be studied alongside this concept?** To fully grasp this, data science students should explore:\n",
    "        * Specific LLM provider APIs for function calling/tool use (e.g., OpenAI's `tools` and `tool_calls` parameters).\n",
    "        * Agentic frameworks like LangChain or LlamaIndex, which provide abstractions and standardized ways to implement these loops.\n",
    "        * State management in conversational AI, as the system needs to maintain context across multiple turns of LLM and tool interactions.\n",
    "        * Designing effective tool descriptions (schemas) so the LLM can reliably request their use.\n",
    "\n",
    "### Code Examples\n",
    "The transcript discusses several code-related aspects:\n",
    "\n",
    "1.  **Core Chat Loop Logic (Conceptual)**:\n",
    "    ```python\n",
    "    # Conceptual structure of the chat loop\n",
    "    messages = [system_prompt_message, user_history, current_user_message]\n",
    "    done = False\n",
    "    while not done:\n",
    "        response = openai.ChatCompletion.create(\n",
    "            model=\"gpt-model-name\",\n",
    "            messages=messages,\n",
    "            tools=tools_json_description  # JSON describing available tools\n",
    "        )\n",
    "        response_message = response.choices[0].message\n",
    "        finish_reason = response.choices[0].finish_reason\n",
    "\n",
    "        if finish_reason == \"tool_calls\":\n",
    "            tool_calls_to_make = response_message.tool_calls\n",
    "            # Append LLM's request to call tools to messages\n",
    "            messages.append(response_message) \n",
    "            \n",
    "            for tool_call in tool_calls_to_make:\n",
    "                # ... logic to identify the function to call (e.g., handle_tool_calls)\n",
    "                # ... execute the actual tool function\n",
    "                tool_result = call_the_tool_function(tool_call.function.name, tool_call.function.arguments)\n",
    "                # Append tool execution result to messages\n",
    "                messages.append(\n",
    "                    {\n",
    "                        \"tool_call_id\": tool_call.id,\n",
    "                        \"role\": \"tool\",\n",
    "                        \"name\": tool_call.function.name,\n",
    "                        \"content\": tool_result, \n",
    "                    }\n",
    "                )\n",
    "            # Loop back to call LLM again with tool results\n",
    "        else: # e.g., finish_reason == \"stop\"\n",
    "            done = True\n",
    "            # final_response_to_user = response_message.content\n",
    "            # return final_response_to_user\n",
    "    ```\n",
    "\n",
    "2.  **File Structure and Key File**:\n",
    "    * `App.py`: The main Python module containing all application code, including tool functions, a class `Me` for the agent, and Gradio interface setup.\n",
    "\n",
    "3.  **Command-Line Operations**:\n",
    "    * Running the app locally (example given, actual command might vary based on local setup):\n",
    "        `urun app.py`\n",
    "    * Deploying to Hugging Face Spaces:\n",
    "        `gradio deploy`\n",
    "\n",
    "4.  **Gradio Interface Setup (Conceptual within `App.py`)**:\n",
    "    ```python\n",
    "    # Conceptual Gradio setup at the end of App.py\n",
    "    # import gradio as gr\n",
    "    # ... (define your chat_function that uses the Me class and its methods) ...\n",
    "    # if __name__ == \"__main__\":\n",
    "    #     iface = gr.ChatInterface(fn=chat_function, title=\"My AI Avatar\")\n",
    "    #     iface.launch()\n",
    "    ```\n",
    "\n",
    "### Reflective Questions\n",
    "1.  **Application:** Beyond a virtual resume, what other specific data science project could leverage the described iterative tool-calling LLM architecture? Provide a one‑sentence explanation.\n",
    "    -   *Answer:* A personalized financial advisory chatbot could use this architecture to fetch real-time stock data, analyze portfolio performance using a code execution tool, and provide tailored recommendations based on user queries.\n",
    "2.  **Teaching:** How would you explain the necessity of the `while not done` loop for tool calling to a junior colleague, as opposed to a single API call, using an analogy?\n",
    "    -   *Answer:* Think of it as a conversation with a research assistant (the LLM): you first ask for information (user prompt), they might say \"I need to check a specific book\" (tool call intent), go check it (tool execution), then come back with the book's info (tool result), and only then can they give you your final, informed answer.\n",
    "3.  **Extension:** What is one potential challenge or limitation when deploying an LLM-based application with tool-calling capabilities to Hugging Face Spaces for public use, and how might it be mitigated?\n",
    "    -   *Answer:* One significant challenge is uncontrolled API usage costs (e.g., for OpenAI calls) if the application gains unexpected popularity or is targeted by bots; this can be mitigated by setting hard spending limits and alerts in the API provider's dashboard, implementing user-specific rate limits within the application if feasible, and potentially adding authentication or a CAPTCHA to the Hugging Face Space.\n",
    "\n",
    "# Day 5 - Deploying Career Conversation Chatbots to Gradio\n",
    "\n",
    "### Summary\n",
    "This transcript details the practical steps of deploying a Python-based AI \"career avatar\" application to Hugging Face Spaces using the `gradio deploy` command. It covers the interactive deployment process, including setting the application title, selecting hardware, and crucially, configuring secrets like API keys for OpenAI and Pushover. The guide then explores embedding the deployed app, suggests numerous exercises for enhancement—such as improving data resources with RAG, adding more sophisticated tools like database integration, and reintegrating an evaluator—and concludes by emphasizing the significant commercial value of such tool-enabled agentic AI in creating interactive and useful business assistants.\n",
    "\n",
    "### Highlights\n",
    "-   **`gradio deploy` Command Workflow**: The deployment leverages the `gradio deploy` command, which guides the user through configuring the app title, specifying the main application file (e.g., `app.py`), choosing hardware (like the free `CPU-basic` tier), and setting up necessary secrets. This command simplifies publishing Gradio apps for data scientists. 🚀\n",
    "-   **Secure Secret Management During Deployment**: A key part of the deployment is providing API keys (e.g., `OPENAI_API_KEY`, `PUSHOVER_USER`, `PUSHOVER_TOKEN`) as \"secrets.\" This ensures sensitive credentials are not hardcoded but are securely available to the application in the hosted Hugging Face Spaces environment. 🛡️\n",
    "-   **Live Demonstration and Testing**: The deployed application is tested live via its Hugging Face Spaces URL. The speaker interacts with it, showcasing its ability to respond to queries and trigger tool-based actions like sending Pushover notifications, confirming the end-to-end functionality. ✅\n",
    "-   **Embedding Deployed Apps**: Hugging Face Spaces allows deployed Gradio applications to be embedded directly into personal websites. This enables a seamless integration of AI tools, like the career avatar, into a data scientist's online portfolio. 🌐\n",
    "-   **Enhancing Knowledge with RAG**: A significant suggested improvement is to expand the chatbot's knowledge by incorporating more detailed personal information or implementing Retrieval Augmented Generation (RAG) with a vector database (e.g., Chroma), allowing for more context-aware responses. 🧠\n",
    "-   **Advanced Tool Integration Capabilities**: The transcript proposes adding more sophisticated tools, such as one for interacting with a SQL database to retrieve past questions and answers or to log new, unanswered ones. This can create a more dynamic and \"learning\" AI agent. 🛠️\n",
    "-   **Reintegrating an Evaluator Component**: To maintain response quality, the idea of re-adding an \"evaluator\" module is suggested. This emphasizes the importance of ongoing quality assurance and refinement in AI applications. 🧐\n",
    "-   **User Interface and Experience Improvements**: Practical suggestions include enhancing the Gradio interface's visual appeal and implementing response streaming. These focus on creating a more polished and engaging user experience. ✨\n",
    "-   **Commercial Value of Tool-Enabled AI**: The discussion highlights that AI assistants gain significant commercial value when they can interact with the real world through tools (e.g., booking services vs. just providing information). This is a crucial point for data scientists aiming to build impactful, real-world applications. 💼\n",
    "-   **AI for Personal Branding**: The \"career avatar\" itself is presented as a tool for personal commercial advantage, allowing data scientists to interactively showcase their skills and attract potential clients or employers. 🧑‍💻\n",
    "\n",
    "### Conceptual Understanding\n",
    "-   **Deploying Gradio Apps with `gradio deploy` and Hugging Face Spaces Secrets**\n",
    "    1.  **Why is this concept important?**\n",
    "        The `gradio deploy` command significantly simplifies publishing local Gradio applications (Python scripts like `app.py`) to Hugging Face Spaces, making AI/ML demos and tools accessible online via a URL. Correctly managing \"secrets\" (like API keys) during this process is paramount for security. It ensures that sensitive information isn't exposed in the public codebase but is securely injected into the application's runtime environment on Hugging Face.\n",
    "    2.  **How does it connect to real‑world tasks, problems, or applications?**\n",
    "        Data scientists and machine learning engineers frequently need to share their models or create interactive demonstrations. Hugging Face Spaces provides a convenient platform for this. For any application that relies on external services (e.g., OpenAI API, notification services like Pushover, databases), securely handling access credentials is a fundamental requirement of real-world deployment to prevent unauthorized access, data breaches, or unexpected financial costs.\n",
    "    3.  **Which related techniques or areas should be studied alongside this concept?**\n",
    "        Alongside `gradio deploy`, it's beneficial to understand:\n",
    "        * **Version Control (Git):** For managing the application code that gets deployed. Hugging Face Spaces are often Git-backed repositories.\n",
    "        * **`requirements.txt`:** Properly defining Python dependencies is crucial for the remote environment to replicate the local setup.\n",
    "        * **Environment Variables:** Understanding how secrets are typically managed as environment variables in cloud hosting environments.\n",
    "        * **Docker (Conceptual):** While `gradio deploy` abstracts many details, Hugging Face Spaces often use Docker containers under the hood. A basic understanding of containerization can be helpful.\n",
    "        * **Hugging Face Spaces Configuration:** Familiarity with Space settings for hardware, visibility (public/private), custom domains, and managing secrets via the web UI if changes are needed post-deployment.\n",
    "        * **Basic CI/CD Principles:** For automating updates to the deployed application (though this was explicitly declined in the walkthrough's GitHub Action prompt).\n",
    "\n",
    "### Code Examples\n",
    "The primary code-related elements discussed are the command-line tool and the sequence of inputs:\n",
    "\n",
    "1.  **Key Deployment Command**:\n",
    "    ```bash\n",
    "    gradio deploy\n",
    "    ```\n",
    "\n",
    "2.  **Conceptual Sequence of `gradio deploy` Prompts and User Inputs**:\n",
    "    * Prompt: `Title for the app` → User provides a title (e.g., `Career Conversations two`).\n",
    "    * Prompt: `Gradio app file (app.py)` → User confirms or specifies the main app file (e.g., `app.py`).\n",
    "    * Prompt: `Spaces hardware (CPU-basic)` → User selects hardware (e.g., `CPU-basic`).\n",
    "    * Prompt: `Any Spaces secrets? (y/N)` → User inputs `Y` (or `Yes`).\n",
    "    * *Loop for adding secrets*:\n",
    "        * Prompt: `Enter the secret name (e.g. OPENAI_API_KEY)` → User inputs the secret's name (e.g., `OPENAI_API_KEY`).\n",
    "        * Prompt: `Enter the value for OPENAI_API_KEY` → User pastes the actual secret value.\n",
    "        * This repeats for other secrets like `PUSHOVER_USER` and `PUSHOVER_TOKEN`.\n",
    "        * Prompt: `Enter blank to to end` → User presses Enter to finish adding secrets.\n",
    "    * Prompt: `Create a GitHub action to automatically update this Space when you push to this repo? (y/N)` → User inputs `N` (or `No`).\n",
    "\n",
    "### Reflective Questions\n",
    "1.  **Application:** How could the suggested exercise of integrating a SQL database tool with the career avatar chatbot enhance its utility for both the user interacting with the bot and the owner of the avatar?\n",
    "    -   *Answer:* For the user, such integration could provide access to a more consistent and curated set of answers to frequently asked questions, which the owner regularly updates. For the owner, it allows the system to log new or unanswered questions, helping them identify knowledge gaps and systematically improve the avatar's responses over time, making it an increasingly valuable asset.\n",
    "2.  **Teaching:** How would you explain to a non-technical project manager why managing `OPENAI_API_KEY` as a \"secret\" during deployment is critical, using a simple analogy?\n",
    "    -   *Answer:* You can explain that the `OPENAI_API_KEY` is like the master key to a company's account for a powerful (and potentially costly) AI service. If this key is left in a public place (like in the code), anyone could find it and use the service, potentially running up large bills or misusing the service under the company's name; keeping it as a \"secret\" is like storing that master key securely in a safe, accessible only by the authorized application.\n",
    "3.  **Extension:** Beyond RAG and SQL tools, what other type of tool could be added to the \"career avatar\" to make it even more interactive or useful for showcasing a data scientist's skills, and why?\n",
    "    -   *Answer:* Integrating a tool that allows the avatar to fetch and display a live, non-sensitive data visualization (e.g., from a public dataset or a predefined analysis related to the data scientist's field) could be very effective. This would directly demonstrate skills in data handling, analysis, and visualization, offering a tangible example of their capabilities beyond just conversational AI.\n",
    "\n",
    "# Day 5 - Foundation Week Wrap-up: Building Complete AI Agents with APIs & Tools\n",
    "\n",
    "### Summary\n",
    "This transcript concludes the first \"Foundational Week\" of a course, celebrating the progress made in understanding AI agents, agentic patterns, API orchestration, and the practical use of resources and tools to build a useful application. It emphasizes that grasping these underlying mechanics of tool integration is valuable for both novices and experienced developers, as this knowledge provides a solid foundation for effectively utilizing higher-level frameworks like the OpenAI Agents SDK, which is the focus of the upcoming week.\n",
    "\n",
    "### Highlights\n",
    "-   **Recap of Foundational Week's Achievements**: The first week successfully covered understanding AI agents, agentic patterns, orchestrating multiple APIs, and the practical application of resources and tools. This learning culminated in building a useful application, providing a tangible outcome for data science students.\n",
    "-   **Intuition Building for Tool Usage**: For learners new to AI tools, the detailed exploration in the course, though potentially intensive, is designed to build intuition about how these systems work. This foundational understanding is crucial for data scientists who will increasingly work with such tools.\n",
    "-   **Advanced Insights on Tool Packaging**: For those with prior experience in tools (e.g., from an \"LM engineering course\"), the week offered insights into elegantly packaging tool usage, highlighting flexibility and the analogy with structured outputs. This is relevant for designing more sophisticated and adaptable agentic AI systems.\n",
    "-   **Importance of Understanding Underlying Mechanisms**: Knowing \"what's going on behind the scenes\" with tool calls and agentic interactions is stressed as highly beneficial. This deeper comprehension allows data scientists to more effectively use and troubleshoot advanced SDKs, like the OpenAI Agents SDK.\n",
    "-   **Preview: OpenAI Agents SDK Focus in Week 2**: The next segment of the course will focus on OpenAI's Agents SDK. The speaker expresses a strong preference for this framework, indicating its significance and practical utility in building AI agents.\n",
    "\n",
    "### Reflective Questions\n",
    "1.  **Application:** Reflecting on the first week's topics (agentic patterns, API orchestration, tools), which specific aspect do you think will be most immediately applicable to a current or future data science project you might undertake? Provide a one‑sentence explanation.\n",
    "    -   *Answer:* The principles of orchestrating calls between multiple different APIs and effectively using external tools are most immediately applicable, as many data science projects require integrating diverse data sources or functionalities to deliver comprehensive solutions.\n",
    "2.  **Teaching:** If you were to explain the importance of understanding \"what's going on behind the scenes\" with AI tools before using a high-level SDK (like the OpenAI Agents SDK) to a junior data scientist, what analogy would you use? Keep it under two sentences.\n",
    "    -   *Answer:* It's similar to understanding basic car mechanics before driving a high-performance vehicle; knowing the fundamentals helps you operate the advanced machinery more effectively, diagnose issues when they arise, and even customize it beyond its standard capabilities.\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
