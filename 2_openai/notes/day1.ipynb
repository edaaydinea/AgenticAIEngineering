{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "507b4a3b",
   "metadata": {},
   "source": [
    "# Understanding Async Python: The Foundation for OpenAI Agents SDK\n",
    "\n",
    "### Summary\n",
    "This guide introduces asynchronous Python (`asyncio`) as a foundational concept for building AI agents, which frequently rely on it. `asyncio` provides a lightweight, single-threaded approach to concurrency, making it ideal for I/O-bound tasks like waiting for responses from LLM APIs. Understanding `asyncio` is crucial for writing efficient, scalable agentic frameworks that can manage many concurrent operations without the overhead of traditional multithreading.\n",
    "\n",
    "### Highlights\n",
    "- **Lightweight Concurrency**: `asyncio` is presented as a simpler, more resource-efficient alternative to multithreading and multiprocessing. Because it doesn't create new OS-level threads, you can run thousands of concurrent tasks, which is perfect for multi-agent systems.\n",
    "- **I/O-Bound Optimization**: It is particularly effective for tasks that spend most of their time waiting for input/output (I/O) operations, such as network requests. When an application calls an LLM API, it's mostly waiting for a response; `asyncio` allows the program to perform other work during these waiting periods instead of blocking.\n",
    "- **Core Keywords: `async` and `await`**: The two fundamental language constructs are `async` and `await`. The `async` keyword is used before a function definition (`async def`) to declare it as a special type of function that can be paused and resumed. The `await` keyword is used to call and wait for the result of these special functions.\n",
    "- **Coroutines vs. Functions**: An `async def` statement defines a **coroutine**, not a regular function. Calling a coroutine (e.g., `my_coro = do_work()`) does not execute its code; it simply creates a coroutine object. To run it, you must `await` it.\n",
    "- **The Event Loop**: `asyncio` uses an **event loop** to manage and schedule coroutines. It runs one coroutine at a time. When a coroutine reaches an `await` call for an I/O operation, the event loop pauses it and switches to another ready coroutine, creating the illusion of parallel execution.\n",
    "- **Concurrent Execution with `asyncio.gather`**: To run multiple coroutines concurrently, you can use `asyncio.gather()`. This function takes multiple coroutine objects, schedules them all on the event loop, and returns a list of their results once all have completed.\n",
    "\n",
    "### Conceptual Understanding\n",
    "- **Coroutines and the Event Loop**\n",
    "  1.  **Why is this concept important?** Understanding the distinction between defining a function and creating a runnable coroutine is the most critical part of `asyncio`. A common beginner mistake is to call an `async` function without `await`, which does nothing and can lead to silent failures. The event loop is the engine that makes this cooperative multitasking possible.\n",
    "  2.  **How does it connect to real-world tasks?** In a multi-agent system, one agent might be waiting for an LLM response while another is querying a database and a third is calling an external API. The event loop efficiently juggles these tasks, ensuring that no single I/O-bound agent blocks the entire application.\n",
    "  3.  **Which related techniques or areas should be studied alongside this concept?** To fully appreciate `asyncio`, it's helpful to compare it with traditional concurrency models like **multithreading** (for CPU-bound tasks in other languages, or for I/O in Python) and **multiprocessing** (for CPU-bound tasks in Python, bypassing the Global Interpreter Lock).\n",
    "\n",
    "### Code Examples\n",
    "- **Defining a Coroutine**\n",
    "  ```python\n",
    "  async def do_some_processing():\n",
    "      # ... some work ...\n",
    "      return \"done\"\n",
    "  ```\n",
    "- **Calling a Coroutine (Incorrectly vs. Correctly)**\n",
    "  ```python\n",
    "  # This does NOT run the code, it just creates an object\n",
    "  my_coroutine = do_some_processing()\n",
    "\n",
    "  # This correctly schedules and runs the coroutine, then gets the result\n",
    "  my_result = await do_some_processing()\n",
    "  ```\n",
    "- **Running Multiple Coroutines Concurrently**\n",
    "  ```python\n",
    "  import asyncio\n",
    "\n",
    "  # Assume three coroutines are defined: do_task_1(), do_task_2(), do_task_3()\n",
    "  results = await asyncio.gather(\n",
    "      do_task_1(),\n",
    "      do_task_2(),\n",
    "      do_task_3()\n",
    "  )\n",
    "  # The 'results' variable will be a list containing the return values of the three tasks.\n",
    "  ```\n",
    "\n",
    "### Reflective Questions\n",
    "1.  **Application:** Which specific dataset or project could benefit from this concept? Provide a one-sentence explanation.\n",
    "    - *Answer*: A financial data pipeline that needs to fetch stock prices from three different web APIs simultaneously would benefit greatly from `asyncio.gather`, as it could make all three network requests concurrently instead of one after another.\n",
    "\n",
    "2.  **Teaching:** How would you explain this idea to a junior colleague, using one concrete example? Keep the answer under two sentences.\n",
    "    - *Answer*: Think of `async/await` like a chef in a kitchen. Instead of staring at one pot until it boils (blocking), the chef starts the water boiling (`await`), then immediately moves on to chop vegetables for another dish, only returning to the pot when it's ready.\n",
    "\n",
    "3.  **Extension:** What related technique or area should you explore next, and why?\n",
    "    - *Answer*: You should explore the difference between `asyncio` and **multithreading** in Python to understand why `asyncio` is superior for I/O-bound tasks while multithreading can be better for tasks that are blocked by non-`asyncio` compatible libraries.\n",
    "\n",
    "# OpenAI Agents SDK Fundamentals: Creating, Tracing, and Running Agents\n",
    "\n",
    "### Summary\n",
    "This lesson introduces the OpenAI Agents SDK, a lightweight and flexible framework for building AI agents. It is designed to be \"unopinionated,\" giving developers more control over their architecture while simplifying common, repetitive tasks like handling the JSON boilerplate for tool use. The SDK is presented as a powerful yet accessible starting point for creating both simple and complex multi-agent systems.\n",
    "\n",
    "### Highlights\n",
    "- **Unopinionated and Flexible**: Unlike \"opinionated\" frameworks that enforce strict design patterns, the OpenAI Agents SDK provides core components without prescribing how they must be used. This offers developers greater flexibility and control, which is ideal for custom solutions.\n",
    "- **Boilerplate Abstraction**: The SDK's primary advantage is abstracting away tedious, error-prone tasks. It automatically handles the complex JSON formatting and logic required for tool and function calls, freeing the developer to focus on the agent's purpose.\n",
    "- **Core Terminology**: The framework introduces three key concepts:\n",
    "    - **Agent**: A wrapper around an LLM call that is assigned a specific role or purpose.\n",
    "    - **Handoff**: The term for interactions or communication between different agents.\n",
    "    - **Guardrails**: A general term for the checks and controls implemented to ensure an agent operates within its intended boundaries and doesn't produce undesirable outcomes.\n",
    "- **Three Steps to Run an Agent**: Executing an agent involves a simple, three-step process:\n",
    "    1.  **Create an Agent Instance**: Instantiate the agent and configure its role.\n",
    "    2.  **Use `with_trace`**: Wrap the execution in a trace context for logging and monitoring, which is crucial for debugging.\n",
    "    3.  **Run with `await runner.run()`**: Call the `run` method on the agent's runner. This method is a **coroutine**, so it must be called with `await`.\n",
    "\n",
    "### Conceptual Understanding\n",
    "- **Opinionated vs. Unopinionated Frameworks**\n",
    "  1.  **Why is this concept important?** The \"opinionated\" nature of a framework fundamentally shapes the development experience. An opinionated framework (e.g., LangChain) provides a lot of structure and pre-built chains, which can accelerate development but may be restrictive. An unopinionated framework like the OpenAI Agents SDK provides essential building blocks but lets the developer decide on the final architecture.\n",
    "  2.  **How does it connect to real-world tasks?** For a standard problem like building a RAG (Retrieval-Augmented Generation) chatbot, an opinionated framework with a pre-built RAG pattern can be very efficient. For a novel, complex multi-agent system where agents have unique interaction patterns, an unopinionated framework provides the necessary freedom to design a custom solution from the ground up.\n",
    "  3.  **Which related techniques or areas should be studied alongside this concept?** This trade-off is common in software engineering. It's useful to explore other examples, such as comparing web frameworks like **Django (opinionated)** with **Flask (unopinionated)**, to understand the broader implications of this design philosophy.\n",
    "\n",
    "### Code Examples\n",
    "- **Conceptual Agent Execution Flow**\n",
    "  ```python\n",
    "  # 1. Create an instance of the agent\n",
    "  # (Specific parameters will depend on the SDK's API)\n",
    "  my_agent = Agent(role=\"Customer Support Assistant\", tools=[...])\n",
    "\n",
    "  # 2. Use with_trace for logging and 3. await the runner\n",
    "  with_trace(name=\"customer_support_interaction\"):\n",
    "      # The runner's run method is a coroutine\n",
    "      response = await my_agent.runner.run(user_query=\"I need help with my order.\")\n",
    "  ```\n",
    "\n",
    "### Reflective Questions\n",
    "1.  **Application:** When would you choose this unopinionated framework over a more structured, opinionated one? Provide a one-sentence explanation.\n",
    "    - *Answer*: You would choose this framework when building a highly customized multi-agent system with unique communication patterns, as its flexibility allows you to define the architecture without fighting against pre-set conventions.\n",
    "\n",
    "2.  **Teaching:** How would you explain the purpose of this SDK to a non-technical project manager? Keep it under two sentences.\n",
    "    - *Answer*: This SDK is a toolkit that lets us build custom AI assistants more easily. It handles all the complicated, repetitive technical wiring for us, so our team can focus on defining what the assistant should do and ensuring it does its job correctly.\n",
    "\n",
    "3.  **Extension:** What is a simple but important \"guardrail\" you might implement for a customer service agent built with this SDK?\n",
    "    - *Answer*: A simple guardrail would be to check the agent's final response for negative sentiment or toxic language before sending it to the user, ensuring the agent always maintains a polite and helpful tone.\n",
    "\n",
    "# Introduction to Agent, Runner, and Trace Classes in OpenAI Agents SDK\n",
    "\n",
    "### Summary\n",
    "This tutorial provides a hands-on walkthrough of creating and running a basic agent using the OpenAI Agents SDK. It covers the essential steps: importing the `Agent`, `Runner`, and `Trace` classes; instantiating an agent with a name, instructions (system prompt), and model; and executing it asynchronously using `await runner.run()`. The lesson emphasizes the importance of the `async/await` pattern and introduces the `with trace(...)` context manager as a powerful tool for logging and monitoring agent interactions within the OpenAI platform.\n",
    "\n",
    "### Highlights\n",
    "- **Core Imports**: To use the SDK, you must import three key components from the `agents` package: `Agent` (to define the agent), `Runner` (to execute it), and `Trace` (to log the interaction).\n",
    "- **Agent Configuration**: An `Agent` is instantiated with several parameters, most importantly `name` (a custom identifier), `instructions` (the system prompt that defines the agent's role and behavior), and `model` (the underlying LLM to use, e.g., `gpt-4-mini`).\n",
    "- **Asynchronous by Design**: The `runner.run()` method is a **coroutine**. Calling it without `await` will only return a coroutine object and will not execute the agent, reinforcing the necessity of using `asyncio` for agentic workflows.\n",
    "- **Correct Execution**: The proper way to run an agent is by using `await runner.run(agent=your_agent, prompt=\"Your message\")`. The final response from the agent is typically accessed via an attribute on the result object, such as `.final_output`.\n",
    "- **Tracing for Observability**: The `with trace(\"your_trace_name\"):` context manager is used to wrap one or more agent interactions. This packages the entire workflow under a single, named trace.\n",
    "- **Monitoring via OpenAI Platform**: These named traces appear in the \"Traces\" section of the OpenAI platform UI. This allows developers to easily inspect the full interaction, including the system prompt, user prompt, and the final assistant response, which is invaluable for debugging complex agent behaviors.\n",
    "- **Model Flexibility**: While the example uses an OpenAI model by default, the SDK is unopinionated and can be configured to work with models from other providers.\n",
    "\n",
    "### Conceptual Understanding\n",
    "- **Tracing for Agent Observability**\n",
    "  1.  **Why is this concept important?** In simple, single-call scenarios, `print()` statements might suffice for debugging. However, as agent workflows grow to include multiple steps, tool calls, and handoffs between agents, it becomes impossible to track the flow of logic. Tracing provides a structured, centralized log of every action the agent takes.\n",
    "  2.  **How does it connect to real-world tasks?** In a production system, if a customer-facing agent provides an incorrect answer, a developer can use the trace to see the exact sequence of events: the initial query, which tools the agent decided to use, the data it got back from those tools, and its final reasoning process. This makes diagnosing the root cause of the failure significantly faster than sifting through unstructured text logs.\n",
    "  3.  **Which related techniques or areas should be studied alongside this concept?** This is a form of **observability**, a critical practice in modern software engineering. It's closely related to **logging**, **monitoring**, and **application performance management (APM)**. Understanding Python's **context managers (`with` statements)** is also essential for using the `trace` feature effectively.\n",
    "\n",
    "### Code Examples\n",
    "- **1. Imports and Environment Setup**\n",
    "  ```python\n",
    "  from dotenv import load_dotenv\n",
    "  from agents import Agent, Runner, Trace\n",
    "\n",
    "  # Load API keys from .env file\n",
    "  load_dotenv(override=True)\n",
    "  ```\n",
    "- **2. Creating an Agent Instance**\n",
    "  ```python\n",
    "  agent = Agent(\n",
    "      name=\"The Jokester\",\n",
    "      instructions=\"You are a joke teller.\",\n",
    "      model=\"gpt-4-mini\",\n",
    "  )\n",
    "  ```\n",
    "- **3. Running the Agent (Correctly, with `await`)**\n",
    "  ```python\n",
    "  # This returns a coroutine object and does NOT run the agent\n",
    "  # result = runner.run(agent=agent, prompt=\"Tell a joke\") \n",
    "\n",
    "  # This correctly executes the agent and waits for the result\n",
    "  result = await Runner.run(\n",
    "      agent=agent, \n",
    "      prompt=\"Tell a joke about autonomous AI agents.\"\n",
    "  )\n",
    "  \n",
    "  print(result.final_output)\n",
    "  ```\n",
    "- **4. Wrapping the Execution in a Trace**\n",
    "  ```python\n",
    "  with Trace(name=\"telling_a_joke\"):\n",
    "      result = await Runner.run(\n",
    "          agent=agent,\n",
    "          prompt=\"Tell a joke about autonomous AI agents.\"\n",
    "      )\n",
    "      print(result.final_output)\n",
    "  ```\n",
    "\n",
    "### Reflective Questions\n",
    "1.  **Application:** How would the `Trace` feature be useful for debugging a multi-step agent that first searches the web for data and then writes a summary?\n",
    "    - *Answer*: The trace would capture both steps in a single view: you could see the exact search query the agent used, the web content it retrieved, and the final summary it generated, making it easy to see if a bad summary was caused by a poor web search or flawed reasoning.\n",
    "\n",
    "2.  **Teaching:** How would you explain to a junior developer why their code `result = runner.run(...)` isn't working and just returns `<coroutine object ...>`?\n",
    "    - *Answer*: I'd explain that `runner.run` is an `async` function, which means it doesn't run immediately; instead, it gives you a \"promise\" of a future result called a coroutine. To actually execute it and get the result, you have to explicitly tell Python to wait for it by putting the `await` keyword in front of the call.\n",
    "\n",
    "3.  **Extension:** The `Agent` class takes a `tools` parameter. What kind of functionality would you add to the \"Jokester\" agent by giving it a tool?\n",
    "    - *Answer*: I could give it a tool named `get_current_date` that returns today's date. This would allow the agent to tell timely, topical jokes, for example: \"Tell me a joke about what's special about `[current_date]`\".\n",
    "\n",
    "# Vibe Coding: 5 Essential Tips for Efficient Code Generation with LLMs\n",
    "\n",
    "### Summary\n",
    "\"Vibe coding,\" a term from Andrej Karpathy, describes a highly productive and interactive workflow for writing code with the assistance of LLMs. This approach involves rapidly generating, tweaking, and iterating on code in a fluid, ad-hoc manner. However, to be successful and avoid common pitfalls like buggy or outdated code, it's crucial to follow a disciplined survival guide, which includes strategies for prompting, verification, incremental development, and validation.\n",
    "\n",
    "### Highlights\n",
    "- **Good Vibes (Effective Prompting)**: Craft high-quality, reusable prompts. Specifically ask for concise, clean code, and always include the current date (e.g., \"use APIs current as of June 2025\") to prevent the LLM from using deprecated functions from its older training data.\n",
    "- **Vibe, but Verify (Cross-Validation)**: Do not blindly trust the output of a single LLM. Ask the same question to multiple models (e.g., ChatGPT and Claude) and compare their answers to identify the most accurate and well-structured solution.\n",
    "- **Step up the Vibe (Incremental Development)**: Avoid generating large, monolithic blocks of code. Instead, ask the LLM to first break the problem down into small, independently testable steps (e.g., 4-5 simple functions). Then, generate and test the code for each small chunk one at a time.\n",
    "- **Vibe and Validate (AI-Powered Code Review)**: Use a second LLM to critique the code generated by the first one. You can prompt it to check for bugs, suggest clearer implementations, or improve conciseness, effectively creating an automated code review process.\n",
    "- **Vibe with Variety (Explore Alternatives)**: Instead of asking for a single solution, prompt the LLM to generate three different ways to solve a problem. This forces the model to explore multiple approaches, potentially uncovering a more elegant solution while also explaining the rationale behind each one, deepening your own understanding.\n",
    "- **Understand Your Code (Avoid Black Boxes)**: The overarching rule of vibe coding is to ensure you understand every line of code that is generated. If something is unclear, ask the LLM to explain it until it makes sense, as this is critical for debugging and maintenance.\n",
    "\n",
    "### Conceptual Understanding\n",
    "- **Structured LLM-Assisted Development**\n",
    "  1.  **Why is this concept important?** The tips collectively transform \"vibe coding\" from a potentially risky, chaotic process into a structured and reliable development methodology. It shifts the developer's role from a passive recipient of code to an active director and validator of an AI pair programmer. This discipline is essential for avoiding technical debt and creating robust, maintainable software.\n",
    "  2.  **How does it connect to real-world tasks?** This structured approach is directly applicable to any development task. When building a complex data processing pipeline, for instance, using the \"Step up the Vibe\" method ensures each transformation step (cleaning, feature engineering, normalization) is correct and testable before being integrated into the whole, dramatically reducing debugging time.\n",
    "  3.  **Which related techniques or areas should be studied alongside this concept?** These principles mirror established software engineering best practices. They are closely related to **Test-Driven Development (TDD)**, **pair programming**, **modular design**, and **code review**. Exploring agentic design patterns like **Generator-Evaluator** is also a logical next step, as it formalizes the \"Vibe and Validate\" process.\n",
    "\n",
    "### Reflective Questions\n",
    "1.  **Application:** How could you apply the \"Step up the Vibe\" principle to a complex data visualization task?\n",
    "    - *Answer*: Instead of asking the LLM to \"create a dashboard for my sales data,\" you would first ask it to outline the steps: 1. Load and clean the data, 2. Create a bar chart for monthly sales, 3. Create a pie chart for sales by region, and 4. Assemble them into a subplot. You would then generate and verify the code for each step individually.\n",
    "\n",
    "2.  **Teaching:** How would you explain the \"Vibe, but Verify\" tip to a junior colleague who relies solely on ChatGPT's first answer?\n",
    "    - *Answer*: I'd tell them to think of it like getting a second opinion from a specialist; even a great expert can miss something or have a particular bias, and checking with another expert (or a different LLM) helps catch errors and often reveals a better, simpler way to solve the problem.\n",
    "\n",
    "3.  **Extension:** The \"Vibe and Validate\" tip manually implements a common agentic pattern. What AI technique could you explore next to automate this process?\n",
    "    - *Answer*: The next step would be to explore or build a simple **Generator-Evaluator agentic system**. In such a system, one agent (the Generator) would be prompted to write the code, and a second agent (the Evaluator) would be automatically prompted to review that code for bugs, style, and correctness, streamlining the validation process.\n",
    "\n",
    "# OpenAI Agents SDK: Understanding Core Concepts for AI Development\n",
    "\n",
    "### Summary\n",
    "This concludes the initial conceptual overview of the OpenAI Agents SDK. The lesson served as a foundation, preparing for a transition from theory to practical application. The next step will be to use these concepts to build a functional project.\n",
    "\n",
    "### Highlights\n",
    "- **Conceptual Phase Complete**: The first day's goal was to understand the basic ideas and terminology of the OpenAI Agents SDK.\n",
    "- **Next Up: Practical Project**: The upcoming lesson will involve building a Sales Development Representative (SDR) agent, applying the learned concepts in a real-world scenario."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
